Guión Detallado - Sesión 10: Casos Prácticos y Proyecto Final - Parte 1
________________________________________
Diapositiva 1: Portada del Curso (2 minutos)
¡Muy buenas noches a todos! Bienvenidos a nuestra décima sesión del curso de Diseño Seguro de Aplicaciones .NET en Azure.
Hoy lunes 28 de julio entramos en territorio absolutamente emocionante. Si en las sesiones anteriores aprendimos la teoría, las herramientas y las metodologías de seguridad como médicos que estudian anatomía y farmacología, hoy nos convertimos en cirujanos que van a operar un paciente real. Vamos a construir desde cero una aplicación que cualquiera de ustedes podría presentar en una entrevista de trabajo o desplegar en un ambiente empresarial.
Piensen en las aplicaciones más exitosas del mundo: Spotify maneja más de 500 millones de usuarios activos; Netflix protege el contenido más valioso de Hollywood; los bancos digitales como Nubank procesan millones de transacciones diariamente. Todas estas organizaciones no solo construyen funcionalidades increíbles, sino que las protegen usando exactamente los mismos principios y tecnologías que implementaremos hoy.
Esta práctica de construir aplicaciones "seguras por diseño" es tan valiosa que las empresas contratan arquitectos especializados que ganan entre $120,000 y $300,000 anuales únicamente para diseñar y supervisar la implementación de estas arquitecturas. Y no es solo por el salario - es porque una sola vulnerabilidad puede costar millones en pérdida de datos, confianza de clientes, y multas regulatorias.
Los patrones de diseño seguro, la integración con Azure AD, y las técnicas de protección de datos que dominaremos hoy son los mismos que usan equipos de desarrollo de Microsoft, Amazon, y Google para mantener seguras aplicaciones que manejan datos de miles de millones de usuarios.
Tenemos 3.5 horas donde van a transformarse de desarrolladores que saben sobre seguridad, a arquitectos que pueden diseñar y construir sistemas inherentemente seguros. Al final de hoy, tendrán en sus manos una aplicación que demuestra dominio profesional de desarrollo seguro en la nube.
________________________________________
Diapositiva 2: Objetivos de la Sesión (3 minutos)
Los objetivos de hoy están diseñados para transformarlos de especialistas teóricos en seguridad a profesionales que pueden arquitectar, diseñar e implementar aplicaciones empresariales completamente seguras desde el primer día.
Primero, diseñaremos una arquitectura segura de extremo a extremo. Imaginen que son los arquitectos principales de una startup fintech que acaba de recibir $50 millones en inversión Serie A. Los inversionistas, los reguladores, y los futuros clientes empresariales esperan que la aplicación sea tan segura como la de un banco tradicional, pero construida con tecnologías modernas de nube. Esa es exactamente la mentalidad que necesitamos.
Segundo, implementaremos una aplicación web .NET Core integral. No vamos a construir un "hola mundo" con algunos controles de seguridad pegados encima. Vamos a crear una aplicación de comercio electrónico completa que incluye autenticación de usuarios, gestión de inventario, procesamiento de pagos simulado, y un panel administrativo. Cada línea de código estará escrita pensando en seguridad desde el primer momento.
Tercero, integraremos Azure AD para autenticación completa. Aquí es donde la teoría se vuelve práctica empresarial real. Configuraremos un sistema de identidad que podría manejar 10,000 usuarios el día del lanzamiento y escalar a 1 millón sin cambios arquitectónicos fundamentales. Esto incluye autenticación multifactor, autorización basada en roles, y gestión de sesiones que cumple estándares empresariales.
Cuarto, configuraremos Key Vault para gestión de secretos. Esto va más allá de simplemente no codificar contraseñas en archivos de configuración. Implementaremos un sistema completo de gestión de secretos que incluye rotación automática, auditoría de acceso, y separación de responsabilidades. Es el tipo de configuración que los auditores de seguridad esperan ver en organizaciones maduras.
Quinto, aplicaremos principios Secure-by-Design en cada decisión. No vamos a agregar seguridad al final como una idea tardía. Cada decisión de diseño - desde cómo estructuramos las bases de datos hasta cómo manejamos los errores - será evaluada a través del lente de seguridad. Es la diferencia entre construir una casa y luego instalar cerraduras, versus diseñar una fortaleza desde los cimientos.
Al final de esta sesión, tendrán en sus computadoras una aplicación completamente funcional que podrían mostrar a un director de tecnología y obtener aprobación para desplegarla en producción. Más importante, entenderán los principios subyacentes para aplicar este conocimiento a cualquier proyecto futuro.
________________________________________
Diapositiva 3: Agenda de la Sesión (2 minutos)
Hemos diseñado esta sesión como una expedición de construcción donde cada etapa nos lleva más profundo en el arte de la arquitectura segura profesional.
Los primeros 25 minutos exploraremos la arquitectura del proyecto final. Es como reunirnos como el equipo arquitectónico de un nuevo rascacielos - antes de tocar una sola herramienta, necesitamos entender exactamente qué vamos a construir, por qué cada decisión de diseño es importante, y cómo todas las piezas encajan juntas.
De 19:25 a 19:50 nos sumergiremos en el diseño seguro de la solución. Aquí es donde transformamos ideas conceptuales en decisiones técnicas específicas. Verán cómo cada patrón de diseño que elegimos, cada tecnología que seleccionamos, y cada configuración que establecemos contribuye a la postura de seguridad general.
De 19:50 a 20:15 estableceremos la configuración base de .NET Core. No vamos a usar un template por defecto y esperar que sea seguro. Configuraremos meticulosamente cada aspecto del proyecto desde middleware de seguridad hasta validación de entrada, desde configuración HTTPS hasta protección contra ataques comunes.
Tomaremos un break de 15 minutos porque la segunda mitad será intensamente técnica y queremos que estén completamente enfocados para la implementación práctica.
De 20:30 a 20:55 integraremos Azure AD en nuestra aplicación. Aquí es donde la teoría se encuentra con la realidad empresarial. Configuraremos un sistema de autenticación que es tan robusto como el que usa Microsoft para sus propios productos internos.
De 20:55 a 21:20 configuraremos Key Vault para gestión segura de secretos. Implementaremos patrones que permiten que la aplicación acceda a secretos sin que ningún desarrollador individual, incluyéndome a mí, pueda ver las credenciales de producción.
Los últimos 70 minutos serán completamente prácticos, donde implementarán cada concepto discutido. Al final de estos laboratorios, tendrán una aplicación que cumple estándares de seguridad que muchas empresas pagan consultores $200,000+ para ayudar a implementar.
________________________________________
Diapositiva 4: Visión del Proyecto Final (4 minutos)
Nuestro proyecto "SecureShop" no es solo otro tutorial de e-commerce. Es una demostración completa de cómo implementar seguridad empresarial en aplicaciones modernas. Imaginen que Netflix decidiera lanzar una tienda online para vender mercancía oficial - esa sería la mentalidad de seguridad que necesitamos.
Las funcionalidades principales han sido elegidas específicamente para demostrar diferentes aspectos de seguridad:
Autenticación con Azure AD y MFA - No vamos a permitir que usuarios se registren con contraseñas débiles como "123456". Implementaremos un sistema donde incluso si alguien descubre la contraseña de un usuario, aún necesita un segundo factor para acceder. Es el mismo nivel de protección que usan los bancos para transacciones de alto valor.
Catálogo de productos con imágenes - Aquí demostraremos cómo manejar archivos subidos por usuarios sin crear vulnerabilidades. ¿Sabían que una de las formas más comunes de comprometer aplicaciones web es subir archivos maliciosos disfrazados como imágenes? Implementaremos protecciones que detectan y previenen estos ataques.
Gestión de carrito de compras - Esta funcionalidad nos permite demostrar autorización basada en recursos. Un usuario debe poder ver y modificar solo su propio carrito, nunca los carritos de otros usuarios. Suena obvio, pero implementarlo correctamente requiere técnicas específicas.
Integración de pagos simulada - Aunque no procesaremos pagos reales, simularemos el flujo completo incluyendo tokenización de datos de tarjetas de crédito y comunicación segura con procesadores de pago. Es el tipo de implementación que debe pasar auditorías PCI DSS.
Panel de administración - Aquí implementaremos el principio de menor privilegio en acción. Los administradores pueden gestionar productos, pero no pueden ver datos de pago. Los gerentes pueden ver reportes, pero no pueden eliminar productos. Cada rol tiene exactamente los permisos que necesita, nada más.
Las características de seguridad van mucho más allá de funcionalidades básicas:
OAuth 2.0 + OpenID Connect - Implementaremos los mismos protocolos que usa Google cuando ustedes hacen "Iniciar sesión con Google" en otras aplicaciones. Es un estándar probado que maneja miles de millones de autenticaciones diariamente.
Autorización basada en roles con Claims - No solo verificaremos si alguien está autenticado, sino que implementaremos permisos granulares. Un usuario con rol "Gerente de Inventario" puede actualizar precios, pero no puede ver datos de clientes.
Encriptación de datos sensibles - Los precios de costo de productos, márgenes de ganancia, y cualquier información de identificación personal estará encriptada en la base de datos. Incluso si alguien roba una copia de la base de datos, no puede leer los datos sensibles sin las claves de encriptación.
Auditoría completa - Cada acción significativa se registrará: quién accedió a qué, cuándo, desde qué dirección IP, y qué cambios hicieron. Es el tipo de trazabilidad que los auditores externos esperan ver en organizaciones serias.
Protección contra OWASP Top 10 - La aplicación estará fortificada contra inyección SQL, cross-site scripting, configuraciones incorrectas de seguridad, y todas las otras vulnerabilidades comunes que aparecen en las noticias cuando las aplicaciones son comprometidas.
Un ejemplo fascinante del mundo real: Target perdió datos de 40 millones de tarjetas de crédito en 2013, lo que resultó en costos de más de $200 millones. SecureShop implementa protecciones específicas que habrían prevenido exactamente ese tipo de ataque.
________________________________________
Diapositiva 5: Stack Tecnológico (3 minutos)
El stack tecnológico que hemos seleccionado representa lo mejor de la tecnología moderna, equilibrando capacidades avanzadas con estabilidad empresarial. Cada decisión ha sido tomada considerando no solo funcionalidad, sino también implicaciones de seguridad.
Para el Frontend, usaremos ASP.NET Core MVC con Razor Pages. ¿Por qué esta elección? Razor Pages proporciona protección automática contra ataques XSS cuando se usa correctamente, y nos permite implementar Content Security Policy de forma natural. Es como tener un guardaespaldas integrado que previene muchos ataques sin esfuerzo adicional.
Bootstrap 5 con CSS Grid no es solo por estética. Bootstrap incluye clases que ayudan a prevenir ataques de clickjacking, y CSS Grid nos permite crear layouts responsivos sin JavaScript adicional que podría introducir vulnerabilidades. Es diseño visual que también contribuye a la seguridad.
JavaScript ES6 con jQuery puede sonar contradictorio - ¿por qué usar jQuery en 2025? Porque jQuery tiene décadas de scrutinio de seguridad y patrones bien establecidos para manejar entrada de usuario de forma segura. ES6 nos da las características modernas de JavaScript, mientras que jQuery proporciona la estabilidad para operaciones críticas de seguridad.
Para el Backend, .NET 8 con Entity Framework Core representa la plataforma más madura para desarrollo empresarial seguro. .NET 8 incluye características de seguridad que no existían en versiones anteriores: mejor gestión de secretos, protección mejorada contra ataques de temporización, y validación automática más robusta.
Azure SQL Database no es solo una base de datos en la nube - es una plataforma de datos que incluye protección avanzada contra amenazas, cifrado transparente, y capacidades de auditoría que cumlen estándares regulatorios. Es la diferencia entre tener una caja fuerte en casa versus tener una bóveda bancaria con sistemas de seguridad de múltiples capas.
Las APIs RESTful seguirán principios de diseño que previenen vulnerabilidades comunes. Implementaremos versionado de API, limitación de tasa, y autenticación de token que resiste ataques de intercepción y replay.
Los Servicios de Azure forman el núcleo de nuestra estrategia de seguridad:
Azure AD para Identity - No vamos a reinventar la gestión de identidades. Azure AD maneja autenticación para más de 1 billón de usuarios globalmente - aprovechemos esa infraestructura probada en lugar de construir algo desde cero.
Key Vault para Secrets - Todos los secretos - claves de API, cadenas de conexión, certificados - estarán almacenados en Key Vault con permisos granulares y auditoría completa. Es como tener un banco suizo para nuestros datos más sensibles.
App Service para Hosting - Proporciona características de seguridad integradas como terminación SSL automática, protección DDoS básica, y aislamiento de aplicaciones. También nos permite implementar deployment slots para testing de seguridad antes de promover cambios a producción.
Application Insights para Monitoring - No solo registraremos errores, sino que implementaremos monitoreo de seguridad que puede detectar patrones de ataque en tiempo real. Es como tener un equipo de analistas de seguridad trabajando 24/7 vigilando nuestra aplicación.
Una analogía útil: Si construir una aplicación tradicional es como construir una casa, construir con este stack es como construir un banco. Cada componente ha sido seleccionado no solo por funcionalidad, sino por resistencia a ataques y capacidad de cumplir con estándares regulatorios estrictos.
Un ejemplo del mundo real: Slack usa un stack tecnológico muy similar para proteger las comunicaciones de más de 12 millones de usuarios diarios activos. Las mismas tecnologías que protegen secretos corporativos de Fortune 500 están disponibles para nosotros.
________________________________________
Diapositiva 6: Arquitectura de Alto Nivel (5 minutos)
La arquitectura segura de extremo a extremo que vamos a implementar representa años de evolución en mejores prácticas de seguridad en la nube. Es como examinar los planos de un banco moderno - cada componente está colocado estratégicamente para crear múltiples capas de protección.
Analicemos cada componente y cómo contribuye a la seguridad general:
Azure AD en la parte superior izquierda actúa como nuestro guardian principal. No es solo un servicio de autenticación - es un ecosistema completo de gestión de identidades que incluye autenticación multifactor que hace que comprometer una cuenta requiera acceso físico al teléfono del usuario, autorización granular que asegura que cada usuario vea solo lo que debe ver, y monitoreo de patrones de acceso que puede detectar cuentas comprometidas automáticamente.
Key Vault en la parte superior central es nuestro depósito de secretos ultrasecreto. Imaginen un banco donde incluso los empleados no pueden ver lo que hay en las cajas de seguridad individuales - esa es la mentalidad de Key Vault. Nuestros desarrolladores pueden desplegar aplicaciones sin nunca ver las contraseñas de producción. Los secretos se rotan automáticamente, el acceso se audita completamente, y las claves están protegidas por módulos de seguridad de hardware.
Azure SQL Database en la parte superior derecha no es una simple base de datos. Incluye cifrado transparente donde los datos están cifrados en disco sin impacto en el rendimiento, control de acceso basado en roles que permite diferentes niveles de acceso para desarrolladores versus administradores, y registros de auditoría que capturan quién accedió a qué datos y cuándo.
La aplicación ASP.NET Core en el centro es donde todo se une. Pero fíjense en las características específicas listadas:
Controladores Seguros - Cada endpoint está diseñado con autorización explícita. No hay páginas "accidentalmente" públicas o funciones administrativas que olvidamos proteger.
Validación de Entrada - Toda entrada de usuario pasa por múltiples capas de validación antes de que llegue a la lógica de negocio. Es como tener múltiples puntos de control de seguridad en un aeropuerto.
Solo HTTPS - No hay tráfico no encriptado, nunca. Incluso en desarrollo local, forzamos HTTPS para construir buenos hábitos desde el principio.
Encabezados CSP (Content Security Policy) - Previenen que scripts maliciosos se ejecuten incluso si alguien logra inyectar código. Es como tener un sistema inmunológico que rechaza código que no reconoce.
Los flujos de datos entre componentes están todos encriptados y autenticados:
La conexión entre la aplicación y Azure AD usa protocolos OAuth 2.0 y OpenID Connect que son resistentes a ataques de intercepción y replay. Incluso si alguien captura el tráfico de red, no pueden usarlo para impersonar usuarios.
La comunicación con Key Vault usa autenticación basada en identidades administradas, lo que significa que no hay credenciales codificadas en la aplicación que puedan ser robadas.
Las consultas a la base de datos usan conexiones encriptadas con validación de certificados, además de consultas parametrizadas que previenen inyección SQL.
La separación de responsabilidades es evidente en el diseño:
•	Azure AD maneja identidad y autenticación - no intentamos duplicar esta funcionalidad
•	Key Vault gestiona secretos - la aplicación nunca almacena credenciales localmente
•	SQL Database maneja persistencia de datos - con encriptación y auditoría integradas
•	La aplicación maneja lógica de negocio - enfocándose en funcionalidad sin comprometer seguridad
Un ejemplo del mundo real: Amazon usa una arquitectura muy similar para AWS Console. Cuando ustedes inician sesión en AWS, pasan por Azure AD (o un sistema equivalente), los secretos se manejan en un sistema como Key Vault, y todas las comunicaciones están encriptadas de extremo a extremo. Estamos implementando el mismo nivel de seguridad que protege infraestructura de nube que vale billones de dólares.
La redundancia de seguridad significa que incluso si un componente falla o es comprometido, las otras capas mantienen el sistema seguro. Es el principio de "defense in depth" aplicado a nivel arquitectónico.
________________________________________
Diapositiva 7: Modelo de Seguridad (4 minutos)
El modelo de seguridad implementado representa la evolución de décadas de aprendizaje sobre cómo proteger aplicaciones empresariales. No es una lista de verificación de características de seguridad - es un sistema integrado donde cada componente refuerza y respalda a los otros.
Los roles de usuario han sido diseñados siguiendo el principio de menor privilegio estricto:
Customer (Cliente) - Puede gestionar su perfil personal, ver productos, manejar su carrito de compras, y ver su historial de pedidos. Aquí está lo crítico: un cliente nunca puede ver datos de otros clientes, acceder a funciones administrativas, o ver información interna como precios de costo. Es como ser un cliente en una tienda física - pueden comprar, pero no pueden entrar a la oficina del gerente.
Manager (Gerente) - Puede gestionar el catálogo de productos, ver reportes de ventas, y administrar inventario. Pero no pueden acceder a datos personales de clientes, ver información de pagos, o realizar funciones de administración del sistema. Es separación de responsabilidades en acción - alguien que gestiona productos no necesita acceso a datos financieros.
Admin (Administrador) - Tiene control completo del sistema, pero incluso los administradores operan bajo principios de auditoría total y no pueden realizar acciones críticas sin dejar rastros auditables. Es poder con responsabilidad.
Las capas de protección forman lo que llamamos "defensa en profundidad":
Capa 1 - Network: HTTPS forzado significa que toda comunicación entre navegadores y nuestro servidor está encriptada usando los mismos estándares que protegen transacciones bancarias. Web Application Firewall (WAF) filtra automáticamente ataques comunes antes de que lleguen a nuestra aplicación.
Capa 2 - Identity: Azure AD con MFA significa que incluso si alguien roba una contraseña, necesitan acceso físico al teléfono del usuario para completar el acceso. Es como requerir tanto una llave como un código biométrico para entrar a una bóveda.
Capa 3 - Application: Validación de entrada asegura que datos maliciosos sean detectados y rechazados antes de que puedan causar daño. Protección CSRF previene que sitios maliciosos engañen a usuarios para realizar acciones no intencionadas.
Capa 4 - Data: Cifrado en reposo significa que incluso si alguien roba físicamente los discos duros donde están almacenados nuestros datos, no pueden leerlos sin las claves de encriptación. Cifrado en tránsito protege datos mientras se mueven entre sistemas.
Capa 5 - Monitoring: Registro y alertas significa que actividad sospechosa se detecta automáticamente, a menudo antes de que los atacantes puedan causar daño real. Es como tener guardias de seguridad que nunca duermen.
El principio "Defense in Depth" significa que el compromiso de cualquier capa individual no resulta en compromiso total del sistema. Si alguien logra bypassear el WAF, aún enfrentan autenticación. Si comprometen una cuenta de usuario, aún están limitados por autorización basada en roles. Si obtienen acceso a la base de datos, los datos sensibles siguen cifrados.
Un ejemplo fascinante del mundo real: En 2017, Equifax fue comprometido a través de una vulnerabilidad de aplicación web no parcheada. Pero el daño masivo ocurrió porque no tenían defensa en profundidad - una vez que los atacantes estuvieron dentro, pudieron moverse lateralmente y acceder a datos no cifrados. Nuestro modelo previene exactamente este tipo de escalación.
Otro ejemplo: Cuando Target fue comprometido en 2013, los atacantes obtuvieron acceso inicial a través de credenciales robadas de un proveedor HVAC. En nuestro modelo, incluso si un proveedor fuera comprometido, el aislamiento de roles y la segmentación de red limitarían severamente qué daño podría causarse.
La implementación práctica significa que cada línea de código que escribimos, cada configuración que establecemos, y cada decisión de despliegue que tomamos será evaluada contra este modelo. No es perfección teórica - es seguridad práctica que funciona en el mundo real.
________________________________________
Diapositiva 8: Threat Model Analysis (4 minutos)
El análisis de amenazas usando STRIDE nos ayuda a pensar sistemáticamente como atacantes para poder defendernos mejor. STRIDE no es solo un acrónimo académico - es una metodología desarrollada por Microsoft que ha sido probada protegiendo sistemas que valen billones de dólares.
Desglosemos cada amenaza y cómo nuestras mitigaciones funcionan en el mundo real:
Spoofing (Suplantación) - Imaginemos un atacante que intenta hacerse pasar por otro usuario. Nuestra mitigación con Azure AD y OAuth 2.0 + JWT significa que incluso si alguien roba credenciales, los tokens tienen expiración corta y requieren validación criptográfica. Es como tener billetes de banco con hologramas imposibles de falsificar que además expiran cada hora.
Un caso real: En 2019, atacantes robaron credenciales de empleados de Twitter y las usaron para acceder a cuentas de alto perfil. Con nuestro sistema de tokens JWT con expiración corta, el impacto habría sido limitado porque los tokens robados se habrían vuelto inútiles rápidamente.
Tampering (Manipulación) - Atacantes intentando modificar datos en tránsito o en almacenamiento. HTTPS previene modificación de datos en tránsito, mientras que firmas digitales nos permiten detectar si datos almacenados han sido alterados. Es como enviar documentos importantes en sobres sellados con sellos de cera únicos.
Repudiation (Repudio) - Usuarios negando que realizaron acciones específicas. Application Insights registra no solo qué acción se realizó, sino quién la realizó, cuándo, desde qué dirección IP, y qué datos estaban involucrados. Es documentación forense que resiste escrutinio legal.
Information Disclosure (Divulgación de Información) - El temor de que datos sensibles sean expuestos a personas no autorizadas. Key Vault asegura que secretos nunca estén hardcodeados en código, mientras que Transparent Data Encryption (TDE) protege datos incluso si alguien obtiene acceso físico a los servidores de base de datos.
Un ejemplo impactante: En 2017, desarrolladores de Uber accidentalmente commitearon claves de AWS a un repositorio público de GitHub. Con nuestro uso de Key Vault, este tipo de exposición accidental es imposible porque los secretos nunca existen en código fuente.
Denial of Service (Denegación de Servicio) - Atacantes intentando hacer que nuestra aplicación no esté disponible. API Throttling limita cuántas peticiones un usuario puede hacer por minuto, previniendo que ataques automatizados abrumen nuestros servidores. Es como tener un bouncer inteligente que puede distinguir entre clientes legítimos y troublemakers.
Elevation of Privilege (Escalación de Privilegios) - La amenaza más insidiosa donde atacantes intentan obtener más permisos de los que deberían tener. Nuestro sistema RBAC asegura que incluso si una cuenta es comprometida, el atacante solo puede realizar acciones que esa cuenta específica estaba autorizada a realizar.
La superficie de ataque minimizada es el resultado de decisiones arquitectónicas específicas:
•	Solo endpoints necesarios están expuestos - no hay páginas de debugging o APIs administrativas accidentalmente públicas
•	Validación de entrada en múltiples capas - datos maliciosos se detectan y rechazan antes de llegar a componentes críticos
•	Principio de menor privilegio - cada componente y usuario tiene exactamente los permisos mínimos necesarios
•	Segmentación de red - incluso si un componente es comprometido, el acceso lateral está restringido
Un framework para evaluación continua: Durante desarrollo, cada nueva característica pasa por análisis STRIDE. Preguntamos: ¿Cómo podría esta funcionalidad ser spoofed? ¿Qué datos podrían ser tampered? ¿Qué información podría ser disclosed? Es pensamiento paranoico aplicado constructivamente.
La mentalidad clave: Los atacantes solo necesitan encontrar una falla, mientras que nosotros necesitamos proteger contra todas las amenazas posibles. STRIDE nos ayuda a ser sistemáticos en lugar de confiar en intuición o suerte.
________________________________________
Diapositiva 9: Estructura del Proyecto (3 minutos) - Continuación
SecureShop.Tests - Pruebas unitarias para lógica de negocio que incluyen casos de prueba específicos para validación de entrada, autorización, y manejo de errores. Es donde verificamos que nuestras defensas funcionen como esperamos.
SecureShop.Security.Tests - Pruebas especializadas para funcionalidades de seguridad que incluyen pruebas de penetración automatizadas, verificación de cifrado, y validación de que los controles de acceso funcionen correctamente. Es como tener un equipo de hackers éticos internos probando constantemente nuestras defensas.
La carpeta docs/ contiene documentación que es crítica para operaciones seguras:
Architecture.md - Documentación técnica que explica decisiones de diseño, patrones de seguridad implementados, y guías para desarrolladores futuros. Esta documentación es lo que permite que nuevos desarrolladores entiendan no solo cómo funciona el código, sino por qué se tomaron decisiones específicas de seguridad.
Security-Review.md - Documentación de revisiones de seguridad que incluye análisis de amenazas, resultados de pruebas de penetración, y planes de remediación para vulnerabilidades encontradas. Es el tipo de documentación que los auditores externos esperan ver.
Los scripts en scripts/ automatizan operaciones críticas:
deploy-azure.ps1 - Script de despliegue que incluye verificaciones de seguridad automáticas antes del despliegue, configuración de recursos Azure con configuraciones seguras por defecto, y validación post-despliegue. Es infraestructura como código con seguridad integrada.
setup-keyvault.ps1 - Script especializado para configurar Key Vault con permisos apropiados, políticas de acceso granulares, y integración con la aplicación. Automatiza pasos complejos que serían propensos a errores si se hicieran manualmente.
La filosofía de separación tiene beneficios de seguridad específicos:
•	Aislamiento de responsabilidades - Si hay una vulnerabilidad en la capa web, no compromete automáticamente la lógica de negocio
•	Reutilización segura - La lógica de negocio puede ser usada por diferentes interfaces sin duplicar reglas de seguridad
•	Auditoría simplificada - Los auditores pueden enfocarse en capas específicas sin perderse en código no relacionado
•	Testing granular - Podemos probar cada capa independientemente, incluyendo escenarios de seguridad específicos
Un ejemplo del mundo real: Microsoft usa una estructura muy similar para sus productos Enterprise. Outlook, Teams, y SharePoint comparten componentes de Core para lógica de negocio, pero tienen capas Web completamente diferentes. Esta arquitectura permitió que cuando se descubrió una vulnerabilidad en la autenticación de SharePoint, la corrección automáticamente protegió otros productos que usaban los mismos componentes Core.
________________________________________
Diapositiva 10: Diseño de Base de Datos (4 minutos)
El modelo de datos seguro que implementaremos va mucho más allá de simples tablas con columnas. Cada decisión de diseño considera implicaciones de seguridad, cumplimiento regulatorio, y auditoría.
Analicemos la tabla Users en detalle:
CREATE TABLE Users (
    Id UNIQUEIDENTIFIER PRIMARY KEY,
    AzureAdObjectId NVARCHAR(50) NOT NULL UNIQUE,
    Email NVARCHAR(100) NOT NULL,
    FirstName NVARCHAR(50),
    LastName NVARCHAR(50),
    CreatedAt DATETIME2 DEFAULT GETDATE(),
    IsActive BIT DEFAULT 1
);
¿Por qué UNIQUEIDENTIFIER para Id? Los GUIDs son imposibles de predecir, lo que previene ataques de enumeración donde atacantes intentan adivinar IDs válidos de usuarios. Con enteros secuenciales, un atacante podría iterar desde 1 hasta 10,000 probando cada ID. Con GUIDs, hay 5.4 × 10^36 posibilidades.
AzureAdObjectId UNIQUE crea la conexión segura entre nuestro sistema y Azure AD. Este ID viene directamente de Azure AD y no puede ser falsificado. Es como tener un número de pasaporte único que vincula la identidad en nuestro sistema con la autenticación external.
¿Por qué no almacenamos contraseñas? Porque Azure AD maneja toda la autenticación, nosotros solo almacenamos la referencia. Incluso si nuestra base de datos es comprometida, no hay contraseñas que robar.
IsActive BIT implementa "soft delete" que es crítico para auditoría. En lugar de eliminar usuarios, los marcamos como inactivos, preservando rastros de auditoría completos. Es requerido por muchas regulaciones de cumplimiento.
La tabla Products demuestra cifrado de datos sensibles:
CREATE TABLE Products (
    Id INT IDENTITY(1,1) PRIMARY KEY,
    Name NVARCHAR(100) NOT NULL,
    Description NVARCHAR(500),
    Price DECIMAL(10,2) NOT NULL,
    Cost VARBINARY(128), -- Encrypted cost data
    CreatedBy UNIQUEIDENTIFIER,
    FOREIGN KEY (CreatedBy) REFERENCES Users(Id)
);
Cost VARBINARY(128) almacena el precio de costo cifrado. ¿Por qué cifrar esto? Porque el margen de ganancia es información competitiva sensible. Incluso empleados que pueden ver precios de venta no deberían ver automáticamente precios de costo.
Un ejemplo real: En 2014, Sony Pictures fue hackeado y se filtraron no solo emails sino también presupuestos detallados de películas, revelando márgenes de ganancia y estrategias de precios. Con nuestro enfoque de cifrado selectivo, incluso si la base de datos es comprometida, la información más sensible permanece protegida.
CreatedBy implementa auditoría automática. Cada producto está vinculado al usuario que lo creó, proporcionando trazabilidad completa. Es fundamental para investigaciones de seguridad y cumplimiento regulatorio.
Patrones de seguridad adicionales que implementaremos:
Auditoría temporal - Cada tabla importante tendrá campos como CreatedAt, UpdatedAt, UpdatedBy para rastrear no solo qué cambió, sino quién lo cambió y cuándo.
Versionado de datos - Para datos críticos, mantendremos versiones históricas para detectar cambios no autorizados y permitir rollback si es necesario.
Cifrado a nivel de fila - Usando Entity Framework, implementaremos cifrado transparente donde datos sensibles se cifran automáticamente antes de guardarse y se descifran automáticamente al leerse, pero solo para usuarios autorizados.
Índices de seguridad - Crearemos índices específicos en campos como AzureAdObjectId y timestamps de auditoría para asegurar que consultas de seguridad críticas sean rápidas incluso con millones de registros.
Separación de datos por sensibilidad:
•	Datos públicos (nombres de productos, descripciones) - sin cifrado especial
•	Datos internos (precios de costo, márgenes) - cifrados con claves de Key Vault
•	Datos personales (información de contacto) - cifrados y sujetos a políticas de retención GDPR
•	Datos de auditoría - almacenados en tablas separadas con permisos de solo-inserción
Un caso de estudio fascinante: Target implementó cifrado después de su brecha de 2013, pero lo hicieron mal - cifraron todo con la misma clave, que estaba almacenada en el mismo servidor. Nuestro enfoque usa diferentes claves para diferentes tipos de datos, almacenadas en Key Vault separado de la aplicación.
________________________________________
Diapositiva 11: Configuración Inicial .NET (5 minutos)
La configuración del proyecto .NET Core desde cero nos permite implementar seguridad desde los cimientos, no como una idea tardía. Cada comando que ejecutemos está diseñado para crear una base sólida para desarrollo empresarial seguro.
Los comandos de creación siguen una secuencia específica que establece arquitectura limpia:
# Crear la solución
dotnet new sln -n SecureShop
Este comando crea la estructura de solución que permitirá gestionar múltiples proyectos relacionados. ¿Por qué es importante para seguridad? Porque nos permite separar responsabilidades desde el inicio, evitando mezclar código de seguridad crítico con lógica de presentación.
# Crear los proyectos individuales
dotnet new web -n SecureShop.Web
dotnet new classlib -n SecureShop.Core
dotnet new classlib -n SecureShop.Data
dotnet new classlib -n SecureShop.Security
Cada tipo de proyecto tiene implicaciones de seguridad específicas:
dotnet new web para SecureShop.Web crea un proyecto web con configuraciones de seguridad habilitadas por defecto en .NET 8, incluyendo protección automática contra ataques comunes y headers de seguridad básicos.
dotnet new classlib para los otros proyectos crea bibliotecas de clases que no tienen superficie de ataque web, reduciendo el riesgo de exposición accidental de funcionalidades internas.
# Agregar proyectos a la solución
dotnet sln add src/SecureShop.Web/SecureShop.Web.csproj
dotnet sln add src/SecureShop.Core/SecureShop.Core.csproj
Esta estructura permite que cada proyecto tenga dependencias específicas sin crear referencias circulares que podrían introducir vulnerabilidades de seguridad.
Los paquetes NuGet esenciales han sido seleccionados por sus capacidades de seguridad probadas:
Microsoft.AspNetCore.Authentication.AzureAD.UI - No es solo para autenticación, sino que incluye protecciones automáticas contra ataques de csrf, validación de tokens robusta, y manejo seguro de redirects. Es como tener un equipo de seguridad especializado en autenticación trabajando en nuestro proyecto.
Azure.Security.KeyVault.Secrets - Proporciona integración nativa con Key Vault que incluye retry automático, manejo de errores específico para operaciones de seguridad, y conexiones encriptadas con validación de certificados. Es mucho más que una simple biblioteca de acceso - es una plataforma de gestión de secretos empresarial.
Microsoft.EntityFrameworkCore.SqlServer - La versión más reciente incluye protección automática contra inyección SQL cuando se usa correctamente, cifrado de conexión por defecto, y capacidades de auditoría integradas. También incluye características como Always Encrypted para cifrado a nivel de columna.
Configuraciones de seguridad adicionales que estableceremos durante la creación:
Configuración de proyecto para análisis de código estático:
<PropertyGroup>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <WarningsAsErrors />
    <WarningsNotAsErrors>NU1605</WarningsNotAsErrors>
    <EnableNETAnalyzers>true</EnableNETAnalyzers>
    <AnalysisMode>AllEnabledByDefault</AnalysisMode>
</PropertyGroup>
Esto configura el compilador para tratar advertencias como errores, forzando que problemas potenciales de seguridad se resuelvan antes de compilación exitosa.
Configuración de dependencias con verificación de seguridad:
<PackageReference Include="Microsoft.AspNetCore.Authentication.AzureAD.UI" Version="8.0.0" />
Especificar versiones exactas previene ataques de dependency confusion donde paquetes maliciosos con nombres similares podrían ser instalados accidentalmente.
Un ejemplo del mundo real: En 2021, desarrolladores de múltiples empresas importantes instalaron accidentalmente paquetes npm maliciosos que tenían nombres similares a paquetes legítimos. Con versionado específico y verificación de fuentes, este tipo de ataque se previene.
La configuración de estructura de carpetas sigue principios de seguridad:
SecureShop/
├── src/              # Código fuente - acceso controlado
├── tests/            # Pruebas - incluye pruebas de seguridad
├── docs/             # Documentación - sin secretos
├── scripts/          # Scripts de automatización - con auditoría
└── .gitignore        # Configurado para excluir archivos sensibles
El archivo .gitignore es crítico para seguridad porque previene que secretos, archivos de configuración local, y otros datos sensibles sean accidentalmente committeados al control de versiones. Incluirá patrones específicos para archivos de Azure, certificados, y configuraciones locales de desarrollo.
La mentalidad desde el primer día: Cada decisión de configuración considera no solo funcionalidad inmediata sino también implicaciones de seguridad a largo plazo. Es mucho más fácil construir sobre una base segura que retro-arreglar seguridad en una aplicación existente.
________________________________________
Diapositiva 12: Configuración de Seguridad Base (4 minutos)
Los headers de seguridad y middleware que configuraremos forman la primera línea de defensa de nuestra aplicación. Son como los sistemas de seguridad perimetral de un edificio corporativo - protegen contra amenazas comunes antes de que lleguen a la lógica de aplicación principal.
Analicemos cada header de seguridad y su propósito:
// Program.cs - Security configuration
app.Use(async (context, next) =>
{
    // Security headers
    context.Response.Headers.Add("X-Frame-Options", "DENY");
    context.Response.Headers.Add("X-Content-Type-Options", "nosniff");
    context.Response.Headers.Add("X-XSS-Protection", "1; mode=block");
    context.Response.Headers.Add("Referrer-Policy", "strict-origin-when-cross-origin");
    
    // CSP Header
    context.Response.Headers.Add("Content-Security-Policy", 
        "default-src 'self'; script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net;");
    
    await next();
});
X-Frame-Options: DENY previene que nuestra aplicación sea incrustada en iframes de otros sitios. ¿Por qué es crítico? Previene ataques de clickjacking donde atacantes superponen elementos invisibles sobre nuestra aplicación para engañar a usuarios a hacer clicks no intencionados. Un ejemplo real: atacantes podrían crear un sitio que parece un juego simple, pero cada click realmente está haciendo transferencias bancarias en nuestra aplicación incrustada de forma invisible.
X-Content-Type-Options: nosniff previene que navegadores "adivinen" el tipo de contenido de archivos. Sin esta protección, un atacante podría subir un archivo .txt que contiene JavaScript malicioso, y algunos navegadores lo ejecutarían como script. Es como tener guardias de seguridad que verifican identificación en lugar de asumir que alguien es quien dice ser basado en su apariencia.
X-XSS-Protection: 1; mode=block activa protecciones integradas del navegador contra ataques de cross-site scripting. Cuando se detecta un ataque XSS, el navegador bloquea completamente la página en lugar de renderizarla con contenido potencialmente malicioso. Es una red de seguridad adicional más allá de nuestras protecciones de aplicación.
Referrer-Policy: strict-origin-when-cross-origin controla qué información se envía cuando usuarios navegan desde nuestra aplicación a otros sitios. Solo enviamos el origen (dominio) cuando navegan a sitios externos, pero enviamos la URL completa para navegación interna. Esto previene que sitios externos vean rutas específicas que podrían revelar información sensible.
Content-Security-Policy (CSP) es el header más poderoso y complejo:
"default-src 'self'; script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net;"
Desglosemos esta política:
default-src 'self' - Por defecto, solo permitir cargar recursos (imágenes, CSS, fonts) desde nuestro propio dominio. Es una política de "confianza cero" hacia contenido externo.
script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net - Para JavaScript, permitir scripts de nuestro dominio, scripts inline (necesario para algunas características de Bootstrap), y específicamente permitir jQuery desde el CDN de jsdelivr. Cada fuente de JavaScript está explícitamente autorizada.
¿Por qué CSP es tan poderoso? Incluso si un atacante logra inyectar código malicioso en nuestra aplicación, CSP previene que se ejecute a menos que venga de una fuente autorizada. Es como tener un sistema inmunológico que rechaza código extraño.
La configuración HTTPS forzada:
// Force HTTPS
app.UseHttpsRedirection();
Este middleware simple asegura que todas las comunicaciones estén encriptadas. Si alguien trata de acceder via HTTP, automáticamente se redirige a HTTPS. En ambientes de producción, configuraremos HSTS (HTTP Strict Transport Security) que instruye a navegadores a nunca intentar conexiones HTTP.
Middleware adicional que configuraremos:
Rate Limiting - Para prevenir ataques de fuerza bruta y abuso de API:
app.UseRateLimiter();
Request Size Limits - Para prevenir ataques de denial of service a través de uploads masivos:
services.Configure<FormOptions>(options =>
{
    options.MultipartBodyLengthLimit = 10 * 1024 * 1024; // 10MB max
});
Session Security - Configuración segura de cookies de sesión:
services.ConfigureApplicationCookie(options =>
{
    options.Cookie.HttpOnly = true;
    options.Cookie.SecurePolicy = CookieSecurePolicy.Always;
    options.Cookie.SameSite = SameSiteMode.Strict;
});
Un ejemplo del mundo real: GitHub implementa headers de seguridad muy similares. Si inspeccionan los headers de respuesta de github.com, verán X-Frame-Options, CSP, y otros headers que son prácticamente idénticos a los que estamos configurando. Estamos implementando el mismo nivel de protección que usan plataformas que manejan código fuente de millones de desarrolladores.
La belleza de este enfoque es que estas protecciones funcionan incluso si hay bugs en nuestro código de aplicación. Son defensas de múltiples capas que operan independientemente de la lógica de negocio.
________________________________________
Diapositiva 13: Entity Framework Seguro (4 minutos)
El contexto de base de datos seguro que implementaremos va mucho más allá de simples operaciones CRUD. Cada aspecto está diseñado para prevenir vulnerabilidades comunes y proporcionar trazabilidad completa de cambios de datos.
Analicemos la configuración del contexto línea por línea:
public class SecureDbContext : DbContext
{
    public SecureDbContext(DbContextOptions<SecureDbContext> options) 
        : base(options) { }

    public DbSet<User> Users { get; set; }
    public DbSet<Product> Products { get; set; }
    public DbSet<AuditLog> AuditLogs { get; set; }
¿Por qué DbSet<AuditLog>? Porque cada cambio importante en la base de datos será registrado automáticamente para auditoría y investigación de seguridad. No es solo logging de errores - es tracking forense de quién cambió qué y cuándo.
    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        // Automatic audit fields
        modelBuilder.Entity<Product>()
            .Property(e => e.CreatedAt)
            .HasDefaultValueSql("GETDATE()");
HasDefaultValueSql("GETDATE()") asegura que timestamps se generen a nivel de base de datos, no en código de aplicación. ¿Por qué es importante para seguridad? Porque timestamps de base de datos no pueden ser falsificados por código malicioso - proporcionan evidencia forense confiable.
        // Data protection for sensitive fields
        modelBuilder.Entity<Product>()
            .Property(e => e.Cost)
            .HasConversion<EncryptedConverter>();
    }
}
EncryptedConverter es donde ocurre la magia del cifrado transparente. Cuando guardamos datos, automáticamente se cifran usando claves de Key Vault. Cuando leemos datos, automáticamente se descifran, pero solo para usuarios autorizados.
Implementemos el EncryptedConverter:
public class EncryptedConverter : ValueConverter<decimal, byte[]>
{
    public EncryptedConverter() : base(
        // Encryption on save
        plaintext => EncryptionService.Encrypt(plaintext.ToString()),
        // Decryption on load  
        ciphertext => decimal.Parse(EncryptionService.Decrypt(ciphertext)))
    {
    }
}
Este converter maneja automáticamente el cifrado bidireccional. Los desarrolladores trabajar con tipos .NET normales (decimal), pero la base de datos almacena solo datos cifrados (byte[]). Es transparencia total para el código de aplicación con seguridad máxima en almacenamiento.
Protecciones automáticas que Entity Framework proporciona:
Consultas parametrizadas automáticas - Cuando escribimos:
var product = context.Products.Where(p => p.Id == productId).FirstOrDefault();
Entity Framework genera automáticamente SQL parametrizado que es inmune a inyección SQL:
SELECT * FROM Products WHERE Id = @p0
Validación de tipos - Entity Framework rechaza automáticamente datos que no coinciden con tipos de modelo definidos. Si intentamos asignar una string de 200 caracteres a un campo definido como NVARCHAR(50), se lanza una excepción antes de que datos inválidos lleguen a la base de datos.
Connection pooling seguro - Entity Framework gestiona pools de conexiones que reutilizan conexiones autenticadas sin exponer credenciales. Es eficiencia de rendimiento con seguridad integrada.
Características de auditoría avanzadas que implementaremos:
Change tracking automático:
public override int SaveChanges()
{
    var auditEntries = ChangeTracker.Entries()
        .Where(e => e.State == EntityState.Added || 
                   e.State == EntityState.Modified || 
                   e.State == EntityState.Deleted)
        .Select(e => new AuditLog
        {
            TableName = e.Entity.GetType().Name,
            Action = e.State.ToString(),
            Changes = JsonSerializer.Serialize(e.CurrentValues.ToObject()),
            Timestamp = DateTime.UtcNow,
            UserId = GetCurrentUserId()
        });

    AuditLogs.AddRange(auditEntries);
    return base.SaveChanges();
}
Este override significa que cada INSERT, UPDATE, o DELETE automáticamente crea un registro de auditoría. No podemos "olvidar" auditar operaciones críticas porque es automático.
Soft delete con preservación de auditoría:
public override int SaveChanges()
{
    foreach (var entry in ChangeTracker.Entries<ISoftDeletable>())
    {
        if (entry.State == EntityState.Deleted)
        {
            entry.State = EntityState.Modified;
            entry.Entity.IsDeleted = true;
            entry.Entity.DeletedAt = DateTime.UtcNow;
        }
    }
    return base.SaveChanges();
}
Soft delete significa que nunca eliminamos realmente datos - solo los marcamos como eliminados. Es crítico para auditoría, cumplimiento regulatorio, y investigaciones de seguridad.
Un ejemplo del mundo real: Cuando Twitter fue comprometido en 2020, los investigadores pudieron rastrear exactamente qué cuentas fueron accedidas, qué tweets fueron enviados, y cuándo, porque tenían auditoría comprensiva similar a la que estamos implementando. Sin estos registros, habría sido imposible determinar el alcance completo del ataque.
La mentalidad clave: Entity Framework no es solo una herramienta de acceso a datos - es una plataforma de gestión de datos seguros cuando se configura correctamente. Cada decisión de configuración debe considerar implicaciones de seguridad, no solo conveniencia de desarrollo.
________________________________________
Diapositiva 14: Input Validation Framework (4 minutos)
La validación de entrada robusta es nuestra primera línea de defensa contra ataques maliciosos. No es solo verificar que los campos requeridos estén presentes - es asegurar que cada byte de datos que entra a nuestro sistema cumple expectativas específicas de formato, longitud, y contenido.
Analicemos el modelo de validación línea por línea:
public class ProductCreateModel
{
    [Required(ErrorMessage = "Name is required")]
    [StringLength(100, MinimumLength = 3)]
    [RegularExpression(@"^[a-zA-Z0-9\s\-\.]+$", 
        ErrorMessage = "Invalid characters in product name")]
    public string Name { get; set; }
¿Por qué múltiples validaciones en un solo campo? Porque los atacantes buscan la validación más débil y la explotan. Es como tener múltiples cerraduras en una puerta - todas deben funcionar para que la seguridad sea efectiva.
[Required] previene que campos críticos sean enviados vacíos o null. Pero no es solo conveniencia de usuario - campos vacíos pueden causar excepciones que revelan información del sistema.
[StringLength(100, MinimumLength = 3)] implementa control de longitud bidireccional. Longitud máxima previene ataques de buffer overflow y denial of service. Longitud mínima previene ataques que dependen de strings vacías o muy cortas para bypassear otras validaciones.
[RegularExpression(@"^[a-zA-Z0-9\s-.]+$")] es donde implementamos validación estricta de contenido. Esta expresión regular permite solo letras, números, espacios, guiones, y puntos. Todo lo demás se rechaza. Es una whitelist approach - solo permitimos caracteres que sabemos son seguros.
    [Required]
    [Range(0.01, 999999.99, ErrorMessage = "Price must be between 0.01 and 999999.99")]
    [DataType(DataType.Currency)]
    public decimal Price { get; set; }
[Range(0.01, 999999.99)] previene valores negativos que podrían usarse para "comprar" productos por dinero negativo (esencialmente recibiendo dinero). También previene valores astronómicos que podrían causar problemas de rendering o cálculo.
[DataType(DataType.Currency)] no solo afecta el display - también instruye al navegador y frameworks de validación sobre qué tipo de entrada esperar, habilitando validaciones adicionales del lado cliente.
    [StringLength(500)]
    [AllowHtml] // Only if absolutely necessary
    public string Description { get; set; }
[AllowHtml] está marcado con un comentario crítico porque HTML en entrada de usuario es extremadamente peligroso. Si necesitamos permitir formateo, implementaremos markdown o un subconjunto muy limitado de HTML, nunca HTML arbitrario.
Validador personalizado para prevenir inyección de scripts:
public class NoScriptInjectionAttribute : ValidationAttribute
{
    public override bool IsValid(object value)
    {
        if (value is string str)
            return !str.Contains("<script", StringComparison.OrdinalIgnoreCase);
        return true;
    }
}
Este validador personalizado busca específicamente intentos de inyección de script. ¿Por qué no usar solo regex más complejas? Porque los atacantes usan múltiples técnicas de evasión - <ScRiPt>, <script , <%script, etc. Es mejor tener múltiples validaciones específicas que una sola validación compleja que podría tener huecos.
Validación en múltiples capas que implementaremos:
Capa 1 - Cliente (JavaScript):
// Validación inmediata para UX, pero no para seguridad
function validateProductName(name) {
    if (name.length < 3) {
        showError("Product name too short");
        return false;
    }
    return true;
}
Capa 2 - Modelo (Data Annotations):
// La validación que acabamos de ver
[Required, StringLength(100, MinimumLength = 3)]
Capa 3 - Servicio de Negocio:
public async Task<Product> CreateProductAsync(ProductCreateModel model)
{
    // Validación adicional específica de negocio
    if (await ProductNameExistsAsync(model.Name))
        throw new BusinessRuleException("Product name already exists");
    
    // Sanitización adicional
    model.Name = SecurityHelper.SanitizeInput(model.Name);
    
    return new Product { Name = model.Name, ... };
}

•	Base de Datos - Protege contra ataques que bypasean completamente la aplicación web
Un ejemplo del mundo real fascinante: En 2019, British Airways fue multada con £20 millones porque su sistema de pagos fue comprometido a través de inyección de script en un campo de entrada que solo tenía validación del lado cliente. Los atacantes modificaron el JavaScript de validación y enviaron código malicioso directamente al servidor. Con nuestro enfoque de múltiples capas, este ataque habría sido bloqueado en al menos tres puntos diferentes.
Manejo de errores de validación seguro:
[HttpPost]
public async Task<IActionResult> CreateProduct(ProductCreateModel model)
{
    if (!ModelState.IsValid)
    {
        // NUNCA retornar detalles internos en mensajes de error
        var errors = ModelState.Values
            .SelectMany(v => v.Errors)
            .Select(e => e.ErrorMessage)
            .Where(msg => !string.IsNullOrEmpty(msg));
        
        // Log detalles completos para análisis interno
        _logger.LogWarning("Validation failed for product creation: {Errors}", errors);
        
        // Retornar solo errores seguros al cliente
        return BadRequest(new { message = "Invalid input provided" });
    }
    
    // Continuar con lógica de creación...
}
Este patrón asegura que información detallada sobre fallas de validación se registre para análisis interno, pero atacantes no reciban información específica que podrían usar para refinar sus ataques.
________________________________________
Diapositiva 15: BREAK (15 minutos)
¡Perfecto! Es momento de tomar un break bien merecido de 15 minutos.
Hemos construido una base arquitectónica sólida sobre cómo diseñar y estructurar aplicaciones empresariales completamente seguras desde el primer día. Ahora comprenden la diferencia entre agregar características de seguridad a una aplicación existente versus construir seguridad directamente en los cimientos.
En el próximo bloque, nos adentraremos en la implementación práctica donde la teoria se transforma en código funcionando. Van a configurar Azure AD paso a paso, implementar Key Vault desde cero, y ver cómo todos estos conceptos arquitectónicos se materializan en una aplicación real.
También exploraremos patrones avanzados de configuración que les permitirán gestionar secretos, certificados, y credenciales con el mismo nivel de sofisticación que usan organizaciones como Microsoft, Netflix, y Spotify para proteger sus propias aplicaciones internas.
Un tip mientras descansan: Piensen en alguna aplicación empresarial que usen en su trabajo diario - sistema de nóminas, plataforma de recursos humanos, herramientas de gestión de proyectos. Todo lo que hemos cubierto hasta ahora está trabajando detrás de escenas en esas aplicaciones. Y todo lo que cubriremos en el próximo bloque es lo que permite que esos sistemas manejen datos sensibles de miles de empleados de forma segura.
Si tienen acceso a Azure, aprovechen para revisar el portal y familiarizarse con las secciones de Azure AD y Key Vault. También pueden explorar los templates de proyecto .NET para ver las diferencias entre configuraciones por defecto y las configuraciones seguras que estamos implementando.
¡Nos vemos a las 20:30! Regresen con energía porque la segunda mitad será donde construimos una aplicación real que podrían desplegar en producción.
________________________________________
Diapositiva 16: Azure AD Registration (5 minutos)
El registro de aplicación en Azure AD es el momento donde nuestra aplicación se convierte en un ciudadano oficial del ecosistema de identidad empresarial. No es solo crear una entrada en una base de datos - es establecer una identidad confiable que puede integrarse con sistemas que manejan millones de usuarios.
Analicemos la configuración paso a paso usando Azure CLI:
# Azure CLI - App Registration
az ad app create \
  --display-name "SecureShop-WebApp" \
  --sign-in-audience "AzureADMyOrg" \
  --web-redirect-uris "https://localhost:5001/signin-oidc" \
  --web-logout-url "https://localhost:5001/signout-callback-oidc"
Desglosemos cada parámetro y su importancia para seguridad:
--display-name "SecureShop-WebApp" - El nombre que aparecerá en logs de auditoría, pantallas de consentimiento, y reportes administrativos. Elegir nombres descriptivos es crítico para operaciones de seguridad - cuando los administradores vean actividad sospechosa, necesitan identificar inmediatamente qué aplicación está involucrada.
--sign-in-audience "AzureADMyOrg" - Restringe el acceso solo a usuarios de nuestra organización Azure AD. Otras opciones como "AzureADMultipleOrgs" o "AzureADandPersonalMicrosoftAccount" ampliarían significativamente la superficie de ataque. Es principio de menor privilegio aplicado a nivel de audiencia.
--web-redirect-uris "https://localhost:5001/signin-oidc" - La URL exacta donde Azure AD enviará usuarios después de autenticación exitosa. ¿Por qué es tan específica? Porque Azure AD solo redirigirá a URLs pre-registradas. Esto previene ataques de open redirect donde atacantes podrían engañar a usuarios para autenticarse y luego ser redirigidos a sitios maliciosos.
--web-logout-url "https://localhost:5001/signout-callback-oidc" - Similar al redirect URI, pero para logout. Controlar el flujo de logout es crítico para asegurar que sesiones se terminen completamente en todos los sistemas involucrados.
# Get Application ID
az ad app list --display-name "SecureShop-WebApp" \
  --query "[0].appId" -o tsv
Este comando obtiene el Application ID único que actuará como la identidad pública de nuestra aplicación. Es como un número de identificación nacional para aplicaciones - único globalmente y usado para rastrear toda la actividad de la aplicación.
Las configuraciones requeridas adicionales que estableceremos:
Redirect URIs específicas por ambiente:
•	Desarrollo: https://localhost:5001/signin-oidc
•	Staging: https://secureshop-staging.azurewebsites.net/signin-oidc
•	Producción: https://secureshop.company.com/signin-oidc
¿Por qué URLs diferentes? Porque cada ambiente debe estar completamente aislado desde perspectiva de identidad. Un token válido para desarrollo nunca debe funcionar en producción.
Token configuration con claims adicionales:
En el portal Azure AD, configuraremos claims opcionales que proporcionan información adicional sobre el usuario sin requerir llamadas adicionales de API:
•	email - Para auditoría y comunicación
•	given_name y family_name - Para personalización de UI
•	groups - Para autorización basada en grupos (si aplicable)
API permissions específicas:
User.Read - Permiso básico para leer perfil del usuario autenticado. Es el permiso mínimo necesario y sigue principio de menor privilegio.
Permisos adicionales que podríamos necesitar (pero solo si son absolutamente necesarios):
•	User.ReadBasic.All - Si necesitamos buscar otros usuarios para características como "asignar tarea a usuario"
•	Group.Read.All - Si implementamos autorización basada en grupos Azure AD
Configuración de certificados y secretos:
En lugar de usar secretos cliente (passwords), configuraremos autenticación basada en certificados para mayor seguridad:
# Generar certificado auto-firmado para desarrollo
az ad app credential reset --id $APP_ID --create-cert --keyvault $KEYVAULT_NAME --cert $CERT_NAME
¿Por qué certificados sobre secretos? Los certificados proporcionan autenticación más fuerte, pueden rotar automáticamente, y están protegidos por HSMs en Key Vault. Los secretos de texto plano son más vulnerables a exposición accidental.
Un ejemplo del mundo real: En 2020, una empresa Fortune 500 tuvo que rotar más de 1,000 secretos de aplicación porque un desarrollador accidentalmente committeó un archivo de configuración que contenía un secreto cliente a un repositorio público. Con certificados almacenados en Key Vault, este tipo de exposición es técnicamente imposible.
Configuración de branding y consentimiento:
Configuraremos logos corporativos, URLs de política de privacidad, y términos de servicio que aparecerán durante el flujo de consentimiento de usuario. Esto no es solo estética - construye confianza de usuario y proporciona transparencia sobre qué permisos está solicitando la aplicación.
La mentalidad clave: Azure AD registration no es un paso de configuración único - es establecer una identidad de aplicación que será auditada, monitoreada, y gestionada a lo largo del ciclo de vida completo de la aplicación.
________________________________________
Diapositiva 17: Configuración Authentication .NET (5 minutos)
La integración de Azure AD en .NET transforma nuestra aplicación de un sistema aislado que maneja su propia autenticación, a un participante sofisticado en un ecosistema de identidad empresarial. Es como la diferencia entre tener guardias propios versus integrarse con un sistema de seguridad coordinado a nivel ciudad.
Analicemos la configuración de autenticación línea por línea:
// Program.cs
builder.Services.AddAuthentication(OpenIdConnectDefaults.AuthenticationScheme)
    .AddMicrosoftIdentityWebApp(options =>
    {
        builder.Configuration.Bind("AzureAd", options);
        options.Events = new OpenIdConnectEvents
        {
            OnTokenValidated = async context =>
            {
                // Custom claims processing
                var userService = context.HttpContext.RequestServices
                    .GetRequiredService<IUserService>();
                await userService.ProcessUserLogin(context.Principal);
            }
        };
    });
AddAuthentication(OpenIdConnectDefaults.AuthenticationScheme) establece OpenID Connect como nuestro mecanismo de autenticación primario. OpenID Connect es el protocolo que usa Google cuando hacen "Sign in with Google", que Microsoft usa para Office 365, y que Apple usa para "Sign in with Apple". Es un estándar probado a escala de miles de millones de usuarios.
AddMicrosoftIdentityWebApp() no es solo una conveniencia - es una configuración específicamente optimizada para integración Azure AD que incluye configuraciones de seguridad que no están habilitadas por defecto en OpenID Connect genérico. Incluye protecciones contra ataques de replay, validación mejorada de tokens, y manejo robusto de errores.
builder.Configuration.Bind("AzureAd", options) carga configuración desde appsettings.json de forma type-safe. Esta configuración nunca incluirá secretos - solo identificadores públicos y URLs. Los secretos vienen de Key Vault.
El evento OnTokenValidated es donde la magia de personalización ocurre:
OnTokenValidated = async context =>
{
    var userService = context.HttpContext.RequestServices
        .GetRequiredService<IUserService>();
    await userService.ProcessUserLogin(context.Principal);
}
¿Qué hace ProcessUserLogin? Aquí es donde vinculamos la identidad Azure AD con nuestro sistema local:
public async Task ProcessUserLogin(ClaimsPrincipal principal)
{
    var azureAdObjectId = principal.GetObjectId();
    var email = principal.GetEmail();
    
    // Buscar o crear usuario local
    var user = await _context.Users
        .FirstOrDefaultAsync(u => u.AzureAdObjectId == azureAdObjectId);
    
    if (user == null)
    {
        // Primer login - crear registro local
        user = new User
        {
            AzureAdObjectId = azureAdObjectId,
            Email = email,
            FirstName = principal.GetGivenName(),
            LastName = principal.GetSurname(),
            CreatedAt = DateTime.UtcNow
        };
        
        _context.Users.Add(user);
        await _context.SaveChangesAsync();
        
        // Log para auditoría de nuevos usuarios
        _logger.LogInformation("New user registered: {Email} with Azure AD ID: {ObjectId}", 
            email, azureAdObjectId);
    }
    else
    {
        // Usuario existente - actualizar última actividad
        user.LastLoginAt = DateTime.UtcNow;
        await _context.SaveChangesAsync();
    }
}
Este proceso de sincronización asegura que tengamos un registro local de cada usuario para auditoría y relaciones de base de datos, mientras que Azure AD maneja toda la autenticación real.
La configuración de políticas de autorización:
// Authorization policies
builder.Services.AddAuthorization(options =>
{
    options.AddPolicy("AdminOnly", policy => 
        policy.RequireRole("Admin"));
    options.AddPolicy("ManagerOrAdmin", policy => 
        policy.RequireRole("Manager", "Admin"));
});
Estas políticas permiten decorar controladores y acciones con autorizaciones específicas:
[Authorize(Policy = "AdminOnly")]
public class AdminController : Controller
{
    // Solo usuarios con rol Admin pueden acceder
}

[Authorize(Policy = "ManagerOrAdmin")]
public async Task<IActionResult> ViewReports()
{
    // Solo Managers y Admins pueden ver reportes
}
Configuración adicional de seguridad que implementaremos:
Cookie Configuration para máxima seguridad:
builder.Services.ConfigureApplicationCookie(options =>
{
    options.Cookie.HttpOnly = true;              // Previene acceso JavaScript
    options.Cookie.SecurePolicy = CookieSecurePolicy.Always;  // Solo HTTPS
    options.Cookie.SameSite = SameSiteMode.Strict;           // Previene CSRF
    options.ExpireTimeSpan = TimeSpan.FromHours(8);          // Expiración de 8 horas
    options.SlidingExpiration = true;                        // Renovar con actividad
});
Timeout de sesión automático:
options.Events.OnRedirectToLogin = context =>
{
    if (context.Request.Path.StartsWithSegments("/api"))
    {
        context.Response.StatusCode = 401;
        return Task.CompletedTask;
    }
    return Task.CompletedTask;
};
Esta configuración asegura que APIs retornen 401 Unauthorized en lugar de redirigir a login, mientras que páginas web normales redirigen apropiadamente.
Un ejemplo del mundo real: Slack usa una configuración de autenticación muy similar. Cuando se autentican en Slack, están pasando por OpenID Connect con Azure AD (si su empresa usa Office 365), y Slack mantiene un registro local de su usuario vinculado a la identidad externa. Es exactamente el mismo patrón que estamos implementando.
La mentalidad de seguridad: Nunca confiamos en tokens sin validación, nunca almacenamos credenciales localmente, y siempre mantenemos auditoría completa de actividad de autenticación. Es una arquitectura diseñada para resistir tanto ataques externos como amenazas internas.
________________________________________
Diapositiva 18: Claims-based Authorization (4 minutos)
La autorización basada en claims representa la evolución de sistemas de permisos simples hacia modelos de seguridad granulares que pueden adaptarse a organizaciones complejas. No es solo verificar si alguien es "administrador" - es construir un sistema flexible que puede manejar permisos específicos, contextuales, y dinámicos.
Analicemos el servicio de transformación de claims:
public class ClaimsTransformationService : IClaimsTransformation
{
    private readonly IUserRoleService _userRoleService;

    public async Task<ClaimsPrincipal> TransformAsync(ClaimsPrincipal principal)
    {
        var identity = (ClaimsIdentity)principal.Identity;
        
        // Get user object ID from Azure AD
        var objectId = principal.GetObjectId();
        
        // Add custom roles from database
        var roles = await _userRoleService.GetUserRolesAsync(objectId);
        
        foreach (var role in roles)
        {
            identity.AddClaim(new Claim(ClaimTypes.Role, role));
        }

        return principal;
    }
}
¿Por qué esta complejidad? Porque Azure AD proporciona identidad, pero no conoce los roles específicos de nuestra aplicación. Un usuario podría ser "Gerente de Inventario" en nuestro sistema, pero Azure AD solo sabe que son empleados de la empresa. La transformación de claims es donde vinculamos identidad externa con autorización específica de aplicación.
El proceso paso a paso:
1.	Azure AD autentica al usuario y proporciona claims básicos como nombre, email, y identificador único
2.	Nuestro sistema usa el identificador único para buscar roles específicos de aplicación en nuestra base de datos local
3.	Agregamos roles como claims adicionales al principal de seguridad
4.	Toda autorización subsecuente usa estos claims enriquecidos
¿Por qué no almacenar roles directamente en Azure AD? Porque los roles de aplicación cambian frecuentemente y son específicos a lógica de negocio. Es separación de responsabilidades - Azure AD maneja "¿quién eres?", nuestro sistema maneja "¿qué puedes hacer aquí?".
Implementación del UserRoleService:
public class UserRoleService : IUserRoleService
{
    private readonly SecureDbContext _context;
    
    public async Task<List<string>> GetUserRolesAsync(string azureAdObjectId)
    {
        var user = await _context.Users
            .Include(u => u.UserRoles)
            .ThenInclude(ur => ur.Role)
            .FirstOrDefaultAsync(u => u.AzureAdObjectId == azureAdObjectId);
        
        if (user == null) return new List<string>();
        
        return user.UserRoles
            .Where(ur => ur.IsActive && ur.Role.IsActive)
            .Select(ur => ur.Role.Name)
            .ToList();
    }
}
Esta implementación incluye verificaciones de estado activo tanto para asignaciones de usuario-rol como para roles themselves. Esto permite desactivar roles temporalmente sin eliminar el historial de asignaciones.
Uso en controladores:
[Authorize(Roles = "Manager,Admin")]
public class ProductController : Controller
{
    [HttpPost]
    public async Task<IActionResult> Create(ProductCreateModel model) 
    { 
        // Solo Managers y Admins pueden crear productos
    }
    
    [HttpDelete("{id}")]
    [Authorize(Roles = "Admin")]
    public async Task<IActionResult> Delete(int id)
    {
        // Solo Admins pueden eliminar productos
    }
}
Autorización más granular usando políticas personalizadas:
// En Program.cs
builder.Services.AddAuthorization(options =>
{
    options.AddPolicy("CanManageInventory", policy =>
        policy.RequireAssertion(context =>
            context.User.IsInRole("Admin") ||
            context.User.IsInRole("InventoryManager") ||
            (context.User.IsInRole("StoreManager") && 
             context.User.HasClaim("StoreLocation", GetCurrentStoreLocation(context)))));
});
Esta política compleja permite que:
•	Admins gestionen inventario en cualquier lugar
•	InventoryManagers gestionen inventario globalmente
•	StoreManagers solo gestionen inventario de su tienda específica
Autorización basada en recursos para casos más complejos:
public class ProductAuthorizationHandler : AuthorizationHandler<OperationAuthorizationRequirement, Product>
{
    protected override Task HandleRequirementAsync(
        AuthorizationHandlerContext context,
        OperationAuthorizationRequirement requirement,
        Product product)
    {
        if (requirement.Name == "Edit")
        {
            if (context.User.IsInRole("Admin") ||
                (context.User.IsInRole("ProductManager") && 
                 product.CreatedBy == context.User.GetUserId()))
            {
                context.Succeed(requirement);
            }
        }
        
        return Task.CompletedTask;
    }
}
Este handler implementa lógica donde usuarios pueden editar productos que crearon, pero solo admins pueden editar productos de otros usuarios. Es autorización contextual que considera tanto el rol del usuario como la relación con el recurso específico.
Un ejemplo del mundo real: GitHub usa autorización basada en claims muy similar. Pueden tener acceso de lectura a repositorios públicos, acceso de escritura a sus propios repositorios, y acceso administrativo a repositorios de su organización. Cada acción verifica claims específicos que consideran tanto su identidad como su relación con el repositorio específico.
La mentalidad de seguridad: La autorización debe ser granular, auditable, y fácil de cambiar sin modificar código. Los roles y permisos evolucionan constantemente en organizaciones reales, así que el sistema debe ser flexible mientras mantiene seguridad estricta.
________________________________________
Diapositiva 19: Key Vault Setup (5 minutos)
Azure Key Vault es mucho más que almacenamiento de secretos - es una plataforma de gestión de material criptográfico de nivel empresarial que proporciona seguridad comparable a módulos de seguridad de hardware de bancos centrales. Imaginen una bóveda bancaria para datos digitales, pero con auditoría automática y control de acceso granular.
Analicemos la creación via Azure CLI paso a paso:
# Create Key Vault
az keyvault create \
  --name "SecureShop-KV-$(date +%s)" \
  --resource-group "SecureShop-RG" \
  --location "East US" \
  --enabled-for-template-deployment \
  --enable-rbac-authorization
¿Por qué $(date +%s) en el nombre? Porque nombres de Key Vault deben ser globalmente únicos a través de todo Azure. Agregar timestamp asegura unicidad mientras mantiene nombres descriptivos. En producción, usaríamos convenciones de nomenclatura organizacionales como "CompanyName-Environment-Purpose-UniqueId".
--enabled-for-template-deployment permite que plantillas ARM y Bicep accedan a Key Vault durante despliegues automáticos. Es crítico para infrastructura como código donde scripts de despliegue necesitan obtener secretos para configurar recursos.
--enable-rbac-authorization es una decisión arquitectónica importante. En lugar de usar access policies tradicionales, usaremos Role-Based Access Control que se integra con Azure AD. Esto significa que permisos de Key Vault se gestionan usando los mismos principios que permisos de Azure resources.
Agregar secretos de forma segura:
# Add secrets
az keyvault secret set \
  --vault-name $KEYVAULT_NAME \
  --name "ConnectionStrings--DefaultConnection" \
  --value $CONNECTION_STRING

az keyvault secret set \
  --vault-name $KEYVAULT_NAME \
  --name "EncryptionKey" \
  --value $(openssl rand -base64 32)
El naming convention "ConnectionStrings--DefaultConnection" mapea directamente a configuración .NET. Cuando nuestro código busca ConnectionStrings:DefaultConnection, Key Vault provider automáticamente lo traduce a ConnectionStrings--DefaultConnection.
$(openssl rand -base64 32) genera una clave de cifrado criptográficamente segura de 256 bits. Esta clave nunca existe en texto plano en archivos de configuración, código fuente, o variables de ambiente. Solo existe en Key Vault protegida por HSMs.
Configuración de Access Policy detallada:
Managed Identity para App Service:
# Habilitar managed identity para la aplicación
az webapp identity assign --name $APP_NAME --resource-group $RESOURCE_GROUP

# Obtener el principal ID de la managed identity
PRINCIPAL_ID=$(az webapp identity show --name $APP_NAME --resource-group $RESOURCE_GROUP --query principalId -o tsv)

# Asignar permisos específicos
az role assignment create \
  --assignee $PRINCIPAL_ID \
  --role "Key Vault Secrets User" \
  --scope "/subscriptions/$SUBSCRIPTION_ID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULT_NAME"
¿Por qué Managed Identity? Porque elimina completamente la necesidad de almacenar credenciales en la aplicación. Azure maneja automáticamente la autenticación entre la aplicación y Key Vault usando identidades que están vinculadas al ciclo de vida del recurso.
Permisos granulares que configuraremos:
Para la aplicación web (Managed Identity):
•	Key Vault Secrets User - Puede leer secretos pero no modificarlos
•	Key Vault Certificate User - Puede usar certificados para operaciones criptográficas
Para desarrolladores (Azure AD Groups):
•	Key Vault Administrator - Puede gestionar Key Vault pero no ver valores de secretos
•	Key Vault Secrets Officer - Puede agregar/actualizar secretos para desarrollo
Para servicios de CI/CD (Service Principal):
•	Key Vault Secrets User - Solo para obtener secretos durante despliegues
Configuración de certificados para operaciones avanzadas:
# Generar certificado para firma digital
az keyvault certificate create \
  --vault-name $KEYVAULT_NAME \
  --name "DataSigningCert" \
  --policy '{
    "keyProperties": {
      "keyType": "RSA",
      "keySize": 2048,
      "exportable": false
    },
    "secretProperties": {
      "contentType": "application/x-pkcs12"
    }
  }'
exportable: false significa que la clave privada nunca puede salir de Key Vault. Todas las operaciones criptográficas ocurren dentro del HSM, proporcionando el máximo nivel de seguridad.
Backup y disaster recovery:
# Configurar backup automático
az backup vault create \
  --name "SecureShop-BackupVault" \
  --resource-group $RESOURCE_GROUP

# Configurar política de backup para Key Vault
az backup policy create \
  --vault-name "SecureShop-BackupVault" \
  --name "KeyVaultDailyBackup" \
  --backup-management-type "AzureKeyVault"
¿Por qué backup de Key Vault? Aunque Azure proporciona alta disponibilidad, los backups protegen contra eliminación accidental de secretos o compromiso de cuenta administrativa. En organizaciones altamente reguladas, backups de material criptográfico pueden ser requerimientos de cumplimiento.
Monitoreo y alertas:
# Configurar logging diagnóstico
az monitor diagnostic-settings create \
  --name "KeyVaultAuditLogs" \
  --resource "/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULT_NAME" \
  --logs '[{"category": "AuditEvent", "enabled": true}]' \
  --workspace $LOG_ANALYTICS_WORKSPACE_ID
AuditEvent logging registra cada acceso a Key Vault - quién accedió a qué secreto, cuándo, desde qué dirección IP, y si el acceso fue exitoso o falló. Es trazabilidad forense completa que cumple requerimientos de auditoría más estrictos.
Un ejemplo del mundo real: Dropbox usa Azure Key Vault (y sistemas equivalentes) para proteger claves de cifrado que protegen archivos de más de 700 millones de usuarios. Incluso empleados de Dropbox con acceso administrativo a servidores no pueden ver las claves de cifrado porque están protegidas por HSMs. Es el mismo nivel de protección que estamos implementando.
________________________________________
Diapositiva 20: Key Vault Integration .NET (5 minutos)
La integración de Key Vault en .NET transforma nuestra aplicación de un sistema que necesita secretos hardcodeados, a una aplicación que puede acceder de forma segura a material criptográfico sin que ningún desarrollador individual pueda ver credenciales de producción. Es como tener un asistente de confianza que puede obtener llaves de una caja fuerte sin que usted tenga que conocer la combinación.
Analicemos la configuración de Key Vault en Program.cs:
// Program.cs - Key Vault configuration
builder.Configuration.AddAzureKeyVault(
    new Uri($"https://{keyVaultName}.vault.azure.net/"),
    new DefaultAzureCredential());
AddAzureKeyVault() es mucho más que una llamada de configuración simple. Automáticamente reemplaza cualquier configuración local con valores de Key Vault, proporciona refresh automático de secretos actualizados, y maneja errores de conectividad con retry inteligente.
DefaultAzureCredential() implementa una cascada de métodos de autenticación:
1.	Managed Identity (en producción en Azure)
2.	Azure CLI credentials (en desarrollo local)
3.	Visual Studio credentials (en desarrollo local)
4.	Environment variables (para CI/CD)
Esta cascada significa que el mismo código funciona en desarrollo, staging, y producción sin cambios, pero usando métodos de autenticación apropiados para cada ambiente.
Servicio de cifrado usando Key Vault:
public class KeyVaultEncryptionService : IEncryptionService
{
    private readonly SecretClient _secretClient;

    public KeyVaultEncryptionService(SecretClient secretClient)
    {
        _secretClient = secretClient;
    }

public async Task<string> EncryptAsync(string plainText)
{
    var keyResponse = await _secretClient.GetSecretAsync("EncryptionKey");
    var key = Convert.FromBase64String(keyResponse.Value.Value);
    
    using var aes = Aes.Create();
    aes.Key = key;
    aes.GenerateIV();
    
    using var encryptor = aes.CreateEncryptor();
    using var msEncrypt = new MemoryStream();
    using var csEncrypt = new CryptoStream(msEncrypt, encryptor, CryptoStreamMode.Write);
    using var swEncrypt = new StreamWriter(csEncrypt);
    
    await swEncrypt.WriteAsync(plainText);
    await swEncrypt.FlushAsync();
    
    // Combinar IV + datos encriptados
    var encryptedData = new byte[16 + msEncrypt.ToArray().Length];
    Array.Copy(aes.IV, 0, encryptedData, 0, 16);
    Array.Copy(msEncrypt.ToArray(), 0, encryptedData, 16, msEncrypt.ToArray().Length);
    
    return Convert.ToBase64String(encryptedData);
}
Esta implementación de cifrado demuestra varias mejores prácticas críticas:
La clave de cifrado viene de Key Vault - nunca está hardcodeada en el código o archivos de configuración. Cada vez que necesitamos cifrar datos, obtenemos la clave fresca de Key Vault.
Generamos un IV (Initialization Vector) único para cada operación - Esto asegura que el mismo texto plano produzca diferentes textos cifrados cada vez. Es crítico para seguridad criptográfica porque previene ataques de análisis de patrones.
Combinamos IV + datos cifrados - El IV no es secreto, pero debe ser único. Al incluirlo con los datos cifrados, simplificamos el manejo mientras mantenemos seguridad.
Uso de using statements - Asegura que material criptográfico sensible se limpie de memoria inmediatamente después del uso. Es defensa contra ataques que intentan leer memoria de procesos.
Configuración de SecretClient en DI container:
// Program.cs - Configuración de servicios
builder.Services.AddSingleton<SecretClient>(provider =>
{
    var keyVaultUrl = builder.Configuration["KeyVault:VaultUri"];
    return new SecretClient(new Uri(keyVaultUrl), new DefaultAzureCredential());
});

builder.Services.AddScoped<IEncryptionService, KeyVaultEncryptionService>();
¿Por qué Singleton para SecretClient? Porque SecretClient maneja connection pooling interno y caching de tokens de autenticación. Crear múltiples instancias sería ineficiente y podría resultar en límites de rate limiting.
¿Por qué Scoped para EncryptionService? Porque cada request HTTP debe tener su propia instancia para evitar problemas de concurrencia, pero puede reutilizar el mismo SecretClient subyacente.
Manejo avanzado de errores y resilencia:
public async Task<string> GetSecretWithRetryAsync(string secretName)
{
    var retryPolicy = Policy
        .Handle<RequestFailedException>()
        .WaitAndRetryAsync(
            retryCount: 3,
            sleepDurationProvider: retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),
            onRetry: (outcome, timespan, retryCount, context) =>
            {
                _logger.LogWarning("Key Vault retry {RetryCount} for secret {SecretName} after {Delay}ms", 
                    retryCount, secretName, timespan.TotalMilliseconds);
            });

    return await retryPolicy.ExecuteAsync(async () =>
    {
        var response = await _secretClient.GetSecretAsync(secretName);
        return response.Value.Value;
    });
}
Esta implementación de retry usa exponential backoff para evitar overwhelming Key Vault durante interrupciones temporales. El primer retry espera 2 segundos, el segundo 4 segundos, el tercero 8 segundos.
Refresh automático de configuración:
// Configurar refresh automático de secretos
builder.Configuration.AddAzureKeyVault(
    new Uri(keyVaultUrl), 
    new DefaultAzureCredential(),
    new AzureKeyVaultConfigurationOptions
    {
        ReloadInterval = TimeSpan.FromMinutes(5),
        Manager = new KeyVaultSecretManager()
    });
ReloadInterval = TimeSpan.FromMinutes(5) significa que la aplicación automáticamente verifica Key Vault cada 5 minutos para secretos actualizados. Si rotamos una clave de API o actualizamos una cadena de conexión, la aplicación recoge el cambio sin restart.
Implementación de caching local con expiración:
public class CachedKeyVaultService : IEncryptionService
{
    private readonly IMemoryCache _cache;
    private readonly KeyVaultEncryptionService _keyVaultService;
    
    public async Task<string> GetEncryptionKeyAsync()
    {
        return await _cache.GetOrCreateAsync("EncryptionKey", async entry =>
        {
            entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(15);
            return await _keyVaultService.GetEncryptionKeyAsync();
        });
    }
}
Este caching reduce llamadas a Key Vault (mejorando rendimiento y reduciendo costos) mientras asegura que claves rotadas se recojan dentro de 15 minutos.
Auditoría de acceso a secretos:
public async Task<string> GetSecretAsync(string secretName)
{
    try
    {
        var secret = await _secretClient.GetSecretAsync(secretName);
        
        // Log acceso exitoso (sin el valor del secreto)
        _logger.LogInformation("Successfully retrieved secret {SecretName} for user {UserId}", 
            secretName, _currentUserService.GetUserId());
        
        return secret.Value.Value;
    }
    catch (Exception ex)
    {
        // Log acceso fallido
        _logger.LogError(ex, "Failed to retrieve secret {SecretName} for user {UserId}", 
            secretName, _currentUserService.GetUserId());
        throw;
    }
}
Esta auditoría registra quién accedió a qué secretos y cuándo, pero nunca registra los valores reales de los secretos. Es trazabilidad completa sin comprometer seguridad.
Un ejemplo del mundo real: Spotify usa una arquitectura muy similar donde microservicios obtienen credenciales de base de datos, claves de API de servicios externos, y certificados SSL de un sistema centralizado de gestión de secretos. Los desarrolladores pueden desplegar código sin nunca ver credenciales de producción, y las claves se rotan automáticamente sin downtime de servicios.
La mentalidad clave: Key Vault no es solo almacenamiento de secretos - es una plataforma de gestión de material criptográfico que permite operaciones de seguridad sofisticadas sin comprometer la facilidad de desarrollo.
________________________________________
Diapositiva 21: Secure Configuration Pattern (4 minutos)
El patrón de configuración segura representa la evolución de gestión de configuración desde archivos con secretos hardcodeados hacia un sistema que separa completamente información pública de material sensible. Es como la diferencia entre dejar un sobre con dinero en su escritorio versus tener referencias a una caja de seguridad.
Analicemos appsettings.json y qué NO debe contener:
// appsettings.json - No secrets here!
{
  "AzureAd": {
    "Instance": "https://login.microsoftonline.com/",
    "Domain": "yourdomain.onmicrosoft.com",
    "TenantId": "[Key Vault Secret: TenantId]",
    "ClientId": "[Key Vault Secret: ClientId]"
  },
  "KeyVault": {
    "VaultUri": "https://secureshop-kv.vault.azure.net/"
  }
}
¿Por qué TenantId y ClientId en Key Vault? Aunque no son secretos en el sentido tradicional, representan información de identificación específica del ambiente. En desarrollo usamos un tenant diferente que en producción. Almacenándolos en Key Vault, el mismo código funciona en múltiples ambientes sin modificación.
Los comentarios "[Key Vault Secret: ...]" son documentación para desarrolladores, indicando que estos valores se reemplazan automáticamente por el Key Vault configuration provider durante startup de la aplicación.
VaultUri es público porque la URL del Key Vault no es sensible - es la autenticación para acceder que está protegida. Es como la dirección de un banco - todos pueden saber dónde está, pero solo clientes autorizados pueden acceder a las cajas de seguridad.
Implementación del servicio de configuración segura:
public class SecureConfigurationService
{
    private readonly IConfiguration _configuration;
    private readonly SecretClient _secretClient;

    public async Task<string> GetConnectionStringAsync()
    {
        // Always fetch from Key Vault, never hardcode
        var secretClient = new SecretClient(vaultUri, credential);
        var secret = await secretClient.GetSecretAsync("ConnectionStrings--DefaultConnection");
        return secret.Value.Value;
    }

    public async Task<DatabaseConfig> GetDatabaseConfigAsync()
    {
        var connectionString = await GetConnectionStringAsync();
        var maxPoolSize = _configuration.GetValue<int>("Database:MaxPoolSize", 100);
        var commandTimeout = _configuration.GetValue<int>("Database:CommandTimeoutSeconds", 30);

        return new DatabaseConfig
        {
            ConnectionString = connectionString,  // From Key Vault
            MaxPoolSize = maxPoolSize,           // From appsettings.json
            CommandTimeout = commandTimeout      // From appsettings.json
        };
    }
}
Esta separación permite que configuraciones no sensibles estén en archivos de configuración normales (para facilidad de cambio), mientras que secretos están protegidos en Key Vault.
Configuración por ambiente usando naming conventions:
// appsettings.Development.json
{
  "KeyVault": {
    "VaultUri": "https://secureshop-dev-kv.vault.azure.net/"
  },
  "Database": {
    "MaxPoolSize": 10,
    "CommandTimeoutSeconds": 60
  }
}

// appsettings.Production.json  
{
  "KeyVault": {
    "VaultUri": "https://secureshop-prod-kv.vault.azure.net/"
  },
  "Database": {
    "MaxPoolSize": 200,
    "CommandTimeoutSeconds": 30
  }
}
Cada ambiente tiene su propio Key Vault, asegurando completo aislamiento entre development, staging, y production. Un desarrollador con acceso a development Key Vault nunca puede acceder accidentalmente a secretos de producción.
Validación de configuración al startup:
public class ConfigurationValidator
{
    public static void ValidateConfiguration(IConfiguration configuration)
    {
        var requiredSettings = new[]
        {
            "KeyVault:VaultUri",
            "AzureAd:Instance",
            "AzureAd:Domain"
        };

        var missingSettings = requiredSettings
            .Where(setting => string.IsNullOrEmpty(configuration[setting]))
            .ToList();

        if (missingSettings.Any())
        {
            throw new InvalidOperationException(
                $"Missing required configuration settings: {string.Join(", ", missingSettings)}");
        }

        // Validate Key Vault accessibility
        try
        {
            var keyVaultUri = configuration["KeyVault:VaultUri"];
            var client = new SecretClient(new Uri(keyVaultUri), new DefaultAzureCredential());
            
            // Test access with a dummy secret call
            _ = client.GetSecretAsync("test-connectivity");
        }
        catch (Exception ex)
        {
            throw new InvalidOperationException("Cannot connect to Key Vault", ex);
        }
    }
}
Esta validación ocurre durante startup de aplicación, fallando rápido si configuración crítica está faltante o Key Vault es inaccesible. Es mejor que la aplicación falle de inmediato que ejecutar con configuración incompleta.
Patrón de configuración con fallback:
public async Task<string> GetConfigValueAsync(string key, string fallbackValue = null)
{
    try
    {
        // Intentar Key Vault primero
        var secret = await _secretClient.GetSecretAsync(key);
        return secret.Value.Value;
    }
    catch (RequestFailedException ex) when (ex.Status == 404)
    {
        // Secret no existe en Key Vault, usar configuración local
        var localValue = _configuration[key];
        if (!string.IsNullOrEmpty(localValue))
        {
            return localValue;
        }

        // Usar valor de fallback si se proporciona
        if (fallbackValue != null)
        {
            return fallbackValue;
        }

        throw new ConfigurationException($"Configuration value '{key}' not found in Key Vault or local configuration");
    }
}
Este patrón de fallback permite degradación graceful si Key Vault está temporalmente inaccesible, mientras registra el problema para investigación.
Configuración de logging que no expone secretos:
public class SafeConfigurationLogger
{
    private readonly string[] _sensitiveKeys = {
        "connectionstring", "password", "secret", "key", "token"
    };

    public void LogConfiguration(IConfiguration configuration)
    {
        foreach (var kvp in configuration.AsEnumerable())
        {
            var isSensitive = _sensitiveKeys.Any(sensitive => 
                kvp.Key.ToLower().Contains(sensitive));

            var valueToLog = isSensitive ? "[REDACTED]" : kvp.Value;
            
            _logger.LogInformation("Configuration: {Key} = {Value}", kvp.Key, valueToLog);
        }
    }
}
Este logging permite diagnosticar problemas de configuración sin accidentalmente registrar secretos en logs que podrían ser vistos por personal no autorizado.
Un ejemplo del mundo real: Netflix usa un patrón muy similar donde configuraciones públicas están en archivos de configuración versionados con el código, mientras que secretos como claves de API y credenciales de base de datos están en un sistema centralizado de gestión de secretos. Esto permite que desarrolladores trabajen localmente sin acceso a credenciales de producción, mientras que el mismo código funciona en todos los ambientes.
La mentalidad clave: La configuración debe ser inmutable por ambiente, versionada con código cuando es pública, y centralizada en sistemas seguros cuando es sensible. Esta separación permite tanto flexibilidad operacional como seguridad rigurosa.
________________________________________
Diapositiva 22: Logging y Auditoría (4 minutos)
El sistema de auditoría completo que implementaremos va mucho más allá de logging básico de errores. Es construir un sistema forense que puede responder preguntas críticas durante investigaciones de seguridad: ¿quién hizo qué, cuándo, desde dónde, y qué cambió exactamente?
Analicemos el modelo AuditLog en detalle:
public class AuditLog
{
    public int Id { get; set; }
    public string UserId { get; set; }        // Quien ejecutó la acción
    public string Action { get; set; }        // Qué acción se realizó
    public string EntityType { get; set; }    // Qué tipo de objeto fue afectado
    public string EntityId { get; set; }      // Cuál objeto específico
    public string Changes { get; set; }       // Qué cambió exactamente
    public DateTime Timestamp { get; set; }   // Cuándo ocurrió
    public string IpAddress { get; set; }     // Desde dónde se originó
    public string UserAgent { get; set; }     // Qué navegador/aplicación
}
Esta estructura permite investigaciones forenses detalladas. Si un producto crítico es eliminado accidentalmente, podemos determinar exactamente quién lo eliminó, cuándo, desde qué ubicación, y qué contenía antes de la eliminación.
Cada campo tiene propósito específico de investigación:
UserId - Vinculado al sistema de identidad para trazabilidad de persona real
Action - CREATE, UPDATE, DELETE, VIEW (para datos sensibles)
EntityType + EntityId - Identificación precisa del objeto afectado
Changes - JSON serializado del estado anterior vs nuevo estado
Timestamp - UTC timestamp para correlación a través de sistemas
IpAddress + UserAgent - Información forense para detectar acceso no autorizado
Implementación del middleware de auditoría:
public class AuditMiddleware
{
    private readonly RequestDelegate _next;
    private readonly ILogger<AuditMiddleware> _logger;

    public async Task InvokeAsync(HttpContext context, RequestDelegate next)
    {
        var stopwatch = Stopwatch.StartNew();
        
        // Capturar información de request
        var originalBody = context.Response.Body;
        using var responseBody = new MemoryStream();
        context.Response.Body = responseBody;

        try
        {
            await next(context);
        }
        finally
        {
            stopwatch.Stop();
            
            if (context.User.Identity.IsAuthenticated)
            {
                await LogUserActivity(context, stopwatch.ElapsedMilliseconds);
            }

            // Restaurar response body
            responseBody.Seek(0, SeekOrigin.Begin);
            await responseBody.CopyToAsync(originalBody);
        }
    }

    private async Task LogUserActivity(HttpContext context, long elapsedMs)
    {
        var auditEntry = new AuditLog
        {
            UserId = context.User.GetUserId(),
            Action = $"{context.Request.Method} {context.Request.Path}",
            EntityType = ExtractEntityType(context.Request.Path),
            EntityId = ExtractEntityId(context.Request.Path),
            Timestamp = DateTime.UtcNow,
            IpAddress = GetClientIpAddress(context),
            UserAgent = context.Request.Headers["User-Agent"].ToString()
        };

        // Solo auditar acciones significativas, no requests estáticos
        if (IsSignificantAction(context.Request.Path, context.Request.Method))
        {
            using var scope = _serviceProvider.CreateScope();
            var auditService = scope.ServiceProvider.GetRequiredService<IAuditService>();
            await auditService.LogAsync(auditEntry);
        }
    }
}
Este middleware captura toda actividad de usuario autenticado automáticamente. No dependemos de que developers recuerden agregar logging - es automático para toda la aplicación.
Auditoría a nivel de Entity Framework:
public override async Task<int> SaveChangesAsync(CancellationToken cancellationToken = default)
{
    var auditEntries = new List<AuditLog>();
    
    foreach (var entry in ChangeTracker.Entries())
    {
        if (entry.Entity is AuditLog || entry.State == EntityState.Detached)
            continue;

        var auditEntry = new AuditLog
        {
            EntityType = entry.Entity.GetType().Name,
            EntityId = GetPrimaryKeyValue(entry),
            UserId = _currentUserService.GetUserId(),
            Timestamp = DateTime.UtcNow,
            IpAddress = _httpContextAccessor.HttpContext?.Connection?.RemoteIpAddress?.ToString()
        };

        switch (entry.State)
        {
            case EntityState.Added:
                auditEntry.Action = "CREATE";
                auditEntry.Changes = JsonSerializer.Serialize(entry.CurrentValues.ToObject());
                break;

            case EntityState.Modified:
                auditEntry.Action = "UPDATE";
                var originalValues = entry.OriginalValues.ToObject();
                var currentValues = entry.CurrentValues.ToObject();
                auditEntry.Changes = JsonSerializer.Serialize(new
                {
                    Before = originalValues,
                    After = currentValues,
                    ModifiedProperties = entry.Properties
                        .Where(p => p.IsModified)
                        .Select(p => p.Metadata.Name)
                        .ToArray()
                });
                break;

            case EntityState.Deleted:
                auditEntry.Action = "DELETE";
                auditEntry.Changes = JsonSerializer.Serialize(entry.OriginalValues.ToObject());
                break;
        }

        auditEntries.Add(auditEntry);
    }

    var result = await base.SaveChangesAsync(cancellationToken);

    // Guardar auditoría después de cambios exitosos
    if (auditEntries.Any())
    {
        AuditLogs.AddRange(auditEntries);
        await base.SaveChangesAsync(cancellationToken);
    }

    return result;
}
Esta implementación captura before/after snapshots completos de cada cambio de datos, permitiendo reconstruir estado histórico completo de cualquier objeto.
Alertas de seguridad basadas en patrones de auditoría:
public class SecurityAlertService
{
    public async Task AnalyzeUserActivity(string userId)
    {
        var recentActivity = await _context.AuditLogs
            .Where(log => log.UserId == userId && log.Timestamp >= DateTime.UtcNow.AddHours(-1))
            .ToListAsync();

        // Detectar actividad sospechosa
        var distinctIPs = recentActivity.Select(a => a.IpAddress).Distinct().Count();
        if (distinctIPs > 3)
        {
            await SendSecurityAlert($"User {userId} accessing from {distinctIPs} different IP addresses in last hour");
        }

        var failedLogins = recentActivity.Count(a => a.Action.Contains("LOGIN") && a.EntityId == "FAILED");
        if (failedLogins > 5)
        {
            await SendSecurityAlert($"User {userId} has {failedLogins} failed login attempts in last hour");
        }

        var dataExports = recentActivity.Count(a => a.Action.Contains("EXPORT") || a.Action.Contains("DOWNLOAD"));
        if (dataExports > 10)
        {
            await SendSecurityAlert($"User {userId} has exported/downloaded {dataExports} items in last hour - possible data exfiltration");
        }
    }
}
Esta análisis detecta patrones de comportamiento anómalos que podrían indicar cuentas comprometidas o actividad maliciosa. Es inteligencia de amenazas basada en comportamiento de usuarios.
Retención y archivado de logs de auditoría:
public async Task ArchiveOldAuditLogs()
{
    var cutoffDate = DateTime.UtcNow.AddYears(-7); // Retención legal de 7 años
    
    var oldLogs = await _context.AuditLogs
        .Where(log => log.Timestamp < cutoffDate)
        .Take(1000) // Procesar en lotes para evitar timeouts
        .ToListAsync();

    if (oldLogs.Any())
    {
        // Exportar a almacenamiento de archivo (Azure Archive Storage)
        await _archiveService.ArchiveAuditLogsAsync(oldLogs);
        
        // Eliminar de base de datos activa
        _context.AuditLogs.RemoveRange(oldLogs);
        await _context.SaveChangesAsync();
    }
}
Este proceso mantiene base de datos de auditoría activa con tamaño manejable mientras preserva registros históricos para cumplimiento regulatorio a largo plazo.
Un ejemplo del mundo real: Cuando Slack investigó el acceso no autorizado a algunos espacios de trabajo en 2022, pudieron determinar exactamente qué datos fueron accedidos, por cuánto tiempo, y desde qué ubicaciones debido a su sistema comprensivo de auditoría. Sin este nivel de logging detallado, habría sido imposible proporcionar garantías específicas a clientes afectados.
La mentalidad de auditoría: Cada acción significativa debe ser registrada de forma que pueda ser reconstruida meses o años después durante investigaciones. No es paranoia - es preparación para realidades operacionales de sistemas que manejan datos valiosos.
________________________________________
Diapositiva 23: Testing de Seguridad (4 minutos)
El testing automatizado de seguridad transforma verificación de controles de seguridad desde procesos manuales propensos a errores hacia validación continua que se ejecuta con cada cambio de código. Es como tener un equipo de ethical hackers ejecutando pruebas 24/7 para asegurar que nuestras defensas funcionen como esperamos.
Analicemos las pruebas de autenticación:
[Test]
public async Task Authentication_RequiredForAdminActions()
{
    // Arrange
    var client = _factory.CreateClient();
    
    // Act - Try to access admin endpoint without auth
    var response = await client.GetAsync("/Admin/Products");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Redirect, response.StatusCode);
    Assert.IsTrue(response.Headers.Location.ToString().Contains("login"));
}
Esta prueba específica verifica que endpoints administrativos redirijan automáticamente a login cuando se accede sin autenticación. ¿Por qué es crítico? Porque si esta protección falla, atacantes pueden acceder directamente a funcionalidades administrativas.
Pero esta prueba también verifica comportamiento específico de redirect:
•	Debe ser redirect (3xx), no error (4xx o 5xx) - para UX apropiada
•	Debe redirigir a URL de login específica - no a página de error genérica
•	No debe exponer información sensible en response body durante redirect
Pruebas de validación de entrada más sofisticadas:
[Test]
public async Task InputValidation_RejectsScriptInjection()
{
    // Arrange
    var model = new ProductCreateModel 
    { 
        Name = "<script>alert('xss')</script>",
        Price = 100 
    };
    
    // Act & Assert
    var validationResults = ValidateModel(model);
    Assert.IsTrue(validationResults.Any(v => v.ErrorMessage.Contains("Invalid characters")));
}

[Test]
public async Task InputValidation_RejectsExcessivelyLongInput()
{
    // Arrange
    var model = new ProductCreateModel 
    { 
        Name = new string('A', 200), // Más largo que el límite de 100 caracteres
        Price = 100 
    };
    
    // Act & Assert
    var validationResults = ValidateModel(model);
    Assert.IsTrue(validationResults.Any(v => v.ErrorMessage.Contains("length")));
}

[Test]
public async Task InputValidation_RejectsNegativePrices()
{
    // Arrange
    var model = new ProductCreateModel 
    { 
        Name = "Valid Product Name",
        Price = -50.00m 
    };
    
    // Act & Assert
    var validationResults = ValidateModel(model);
    Assert.IsTrue(validationResults.Any(v => v.ErrorMessage.Contains("between")));
}
Estas pruebas verifican múltiples vectores de ataque diferentes: XSS injection, buffer overflow attempts, y lógica de negocio maliciosa. Cada prueba se enfoca en un tipo específico de entrada maliciosa.
Testing de autorización basada en roles:
[Test]
public async Task Authorization_ManagerCanAccessReports()
{
    // Arrange
    var client = await CreateAuthenticatedClient("manager@company.com", roles: ["Manager"]);
    
    // Act
    var response = await client.GetAsync("/Reports/Sales");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.OK, response.StatusCode);
}

[Test]
public async Task Authorization_CustomerCannotAccessReports()
{
    // Arrange
    var client = await CreateAuthenticatedClient("customer@email.com", roles: ["Customer"]);
    
    // Act
    var response = await client.GetAsync("/Reports/Sales");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Forbidden, response.StatusCode);
}

[Test]
public async Task Authorization_UserCanOnlyAccessOwnData()
{
    // Arrange
    var user1Client = await CreateAuthenticatedClient("user1@email.com", userId: "user1");
    var user2Client = await CreateAuthenticatedClient("user2@email.com", userId: "user2");
    
    // User1 crea un pedido
    var createResponse = await user1Client.PostAsJsonAsync("/api/orders", new { ProductId = 1, Quantity = 2 });
    var orderId = await ExtractOrderIdFromResponse(createResponse);
    
    // Act - User2 intenta acceder al pedido de User1
    var accessResponse = await user2Client.GetAsync($"/api/orders/{orderId}");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Forbidden, accessResponse.StatusCode);
}
Esta última prueba es particularmente importante porque verifica aislamiento de datos entre usuarios. Es el tipo de bug que resulta en exposición masiva de datos cuando no se detecta.
Testing de seguridad de API:
[Test]
public async Task API_RequiresValidJWTToken()
{
    // Arrange
    var client = _factory.CreateClient();
    
    // Act - Call API without token
    var response = await client.GetAsync("/api/products");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Unauthorized, response.StatusCode);
}

[Test]
public async Task API_RejectsExpiredJWTToken()
{
    // Arrange
    var expiredToken = GenerateExpiredJWT();
    var client = _factory.CreateClient();
    client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", expiredToken);
    
    // Act
    var response = await client.GetAsync("/api/products");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Unauthorized, response.StatusCode);
}

[Test]
public async Task API_RejectsManipulatedJWTToken()
{
    // Arrange
    var validToken = await GenerateValidJWT("user@email.com");
    var manipulatedToken = validToken.Replace("user@email.com", "admin@email.com");
    
    var client = _factory.CreateClient();
    client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", manipulatedToken);
    
    // Act
    var response = await client.GetAsync("/api/admin/users");
    
    // Assert
    Assert.AreEqual(HttpStatusCode.Unauthorized, response.StatusCode);
}
Esta prueba verifica que tokens JWT manipulados sean rechazados debido a falla de validación de firma. Es crítico porque atacantes a menudo intentan modificar claims en tokens para escalar privilegios.
Testing de protección contra ataques comunes:
[Test]
public async Task Security_PreventsCSRFAttacks()
{
    // Arrange
    var client = _factory.CreateClient();
    var authenticatedClient = await CreateAuthenticatedClient("user@email.com");
    
    // Obtener token CSRF válido
    var getResponse = await authenticatedClient.GetAsync("/Products/Create");
    var csrfToken = ExtractCSRFTokenFromHTML(await getResponse.Content.ReadAsStringAsync());
    
    // Act - Intentar POST sin token CSRF desde cliente diferente
    var postData = new FormUrlEncodedContent(new[]
    {
        new KeyValuePair<string, string>("Name", "Malicious Product"),
        new KeyValuePair<string, string>("Price", "999")
        // Sin token CSRF
    });
    
    var response = await client.PostAsync("/Products/Create", postData);
    
    // Assert
    Assert.AreEqual(HttpStatusCode.BadRequest, response.StatusCode);
}

[Test]
public async Task Security_PreventsExcessiveRequestRate()
{
    // Arrange
    var client = _factory.CreateClient();
    var tasks = new List<Task<HttpResponseMessage>>();
    
    // Act - Enviar 100 requests simultáneos
    for (int i = 0; i < 100; i++)
    {
        tasks.Add(client.GetAsync("/api/products"));
    }
    
    var responses = await Task.WhenAll(tasks);
    
    // Assert - Algunas requests deben ser rate limited
    var rateLimitedResponses = responses.Count(r => r.StatusCode == HttpStatusCode.TooManyRequests);
    Assert.IsTrue(rateLimitedResponses > 0, "Rate limiting should reject some requests");
}
Estas pruebas verifican protecciones contra ataques CSRF y rate limiting funcionan como esperamos. Son controles de seguridad que deben funcionar automáticamente sin intervención de developer.
Testing de cifrado y protección de datos:
[Test]
public async Task DataProtection_EncryptsSensitiveFields()
{
    // Arrange
    var product = new Product
    {
        Name = "Test Product",
        Price = 100.00m,
        Cost = 75.00m // Campo sensible que debe cifrarse
    };
    
    // Act
    _context.Products.Add(product);
    await _context.SaveChangesAsync();
    
    // Assert - Verificar que cost está cifrado en base de datos
    var rawSql = "SELECT Cost FROM Products WHERE Id = @id";
    var encryptedCost = await _context.Database
        .SqlQueryRaw<byte[]>(rawSql, new SqlParameter("@id", product.Id))
        .FirstAsync();
    
    // El costo cifrado no debe ser igual al valor original
    var originalCostBytes = BitConverter.GetBytes((double)product.Cost);
    Assert.IsFalse(encryptedCost.SequenceEqual(originalCostBytes));
    
    // Pero al leer a través de Entity Framework debe descifrarse correctamente
    var retrievedProduct = await _context.Products.FindAsync(product.Id);
    Assert.AreEqual(75.00m, retrievedProduct.Cost);
}
Esta prueba verifica que el cifrado transparente funciona correctamente - datos están cifrados en almacenamiento pero accesibles normalmente a través de la aplicación.
Integration testing con Azure AD:
[Test]
public async Task AzureAD_Integration_WorksEndToEnd()
{
    // Esta prueba requiere ambiente de prueba con Azure AD real
    if (!IsIntegrationTestEnvironment()) return;
    
    // Arrange
    var client = _factory.CreateClient();
    
    // Act - Simular flujo completo de autenticación
    var loginResponse = await client.GetAsync("/Account/Login");
    var redirectLocation = ExtractAzureADRedirectURL(loginResponse);
    
    // Simular respuesta de Azure AD (en ambiente de prueba)
    var authCode = await SimulateAzureADAuthenticationFlow(redirectLocation);
    var callbackResponse = await client.GetAsync($"/signin-oidc?code={authCode}");
    
    // Assert
    Assert.IsTrue(callbackResponse.Headers.Contains("Set-Cookie"));
    
    // Verificar que usuario autenticado puede acceder recursos protegidos
    var protectedResponse = await client.GetAsync("/Dashboard");
    Assert.AreEqual(HttpStatusCode.OK, protectedResponse.StatusCode);
}
Testing de performance de seguridad:
[Test]
public async Task Security_EncryptionDoesNotDegradePerformance()
{
    // Arrange
    var stopwatch = new Stopwatch();
    var products = GenerateTestProducts(1000);
    
    // Act - Medir tiempo de inserción con cifrado
    stopwatch.Start();
    _context.Products.AddRange(products);
    await _context.SaveChangesAsync();
    stopwatch.Stop();
    
    var encryptionTime = stopwatch.ElapsedMilliseconds;
    
    // Assert - Cifrado no debe agregar más de 50% overhead
    var expectedMaxTime = 1000; // 1 segundo para 1000 productos
    Assert.IsTrue(encryptionTime < expectedMaxTime, 
        $"Encryption took {encryptionTime}ms, expected less than {expectedMaxTime}ms");
}
Automatización de testing de seguridad en CI/CD:
# azure-pipelines.yml
- task: DotNetCoreCLI@2
  displayName: 'Run Security Tests'
  inputs:
    command: 'test'
    projects: '**/SecureShop.Security.Tests.csproj'
    arguments: '--configuration Release --logger trx --collect:"XPlat Code Coverage" --filter Category=Security'

- task: PublishTestResults@2
  displayName: 'Publish Security Test Results'
  inputs:
    testResultsFormat: 'VSTest'
    testResultsFiles: '**/*.trx'
    failTaskOnFailedTests: true
Esta configuración asegura que pruebas de seguridad se ejecuten automáticamente en cada build, y fallen el pipeline si cualquier prueba de seguridad falla.
Un ejemplo del mundo real: GitHub ejecuta miles de pruebas de seguridad automatizadas cada vez que deployan código. En 2021, sus pruebas automatizadas detectaron una regresión que habría permitido acceso no autorizado a repositorios privados antes de que llegara a producción. La automatización de testing de seguridad previno lo que podría haber sido una brecha masiva de datos.
La mentalidad de testing de seguridad: Cada control de seguridad debe ser verificado automáticamente, y fallos de seguridad deben prevenir despliegues. No es suficiente implementar seguridad - debemos probar continuamente que funciona como esperamos.
________________________________________
Diapositiva 24: Próximos Pasos (3 minutos)
¡Hemos completado una jornada arquitectónica extraordinaria! En estas dos horas de conceptos intensivos, se han transformado de desarrolladores que conocen sobre seguridad a arquitectos que pueden diseñar, implementar y mantener aplicaciones empresariales completamente seguras desde el primer día.
La próxima sesión del miércoles 30 de julio marca la continuación del Módulo 5 con Casos Prácticos - Parte 2, donde completarán la implementación práctica de todo lo arquitecturado hoy.
La finalización de autenticación y autorización será nuestro enfoque inicial. Implementarán claims transformations personalizadas, autorización basada en recursos, y políticas de seguridad granulares que pueden adaptarse a organizaciones con miles de usuarios y docenas de roles diferentes.
La implementación de firma digital los introduce a criptografía avanzada donde aprenderán a usar Azure Key Vault no solo para almacenar secretos, sino para operaciones criptográficas sofisticadas como firma y verificación de documentos. Es el tipo de funcionalidad que permite a organizaciones cumplir requerimientos de no-repudio y integridad de documentos.
La encriptación de datos de aplicación completará el círculo de protección donde implementarán cifrado a nivel de campo, gestión de claves con rotación automática, y técnicas de cifrado que permiten operaciones de búsqueda en datos cifrados. Es tecnología que usan bancos y organizaciones de salud para proteger información altamente sensible.
Las pruebas integrales de seguridad incluirán ejecución de herramientas de análisis de vulnerabilidades, pruebas de penetración automatizadas, y validación de cumplimiento contra marcos como OWASP Top 10 y NIST Cybersecurity Framework.
Para prepararse efectivamente para la próxima sesión, recomiendo:
Completar la configuración de Azure AD - Crear al menos una aplicación de prueba, experimentar con diferentes tipos de claims, y familiarizarse con el flujo de consentimiento administrativo. La experiencia práctica construirá confianza para cuando implementemos integraciones complejas.
Explorar características avanzadas de Key Vault - Particularmente certificados, operaciones de cifrado, y políticas de acceso. Intentar crear certificados auto-firmados y usar Key Vault para operaciones de firma.
Revisar patrones de encriptación en .NET 8 - Especialmente nuevas APIs de criptografía, mejoras en Data Protection, y integración con proveedores de hardware de seguridad.
La preparación para evaluación final comienza ahora. El proyecto que completarán en las próximas dos sesiones será lo que presenten como demostración de dominio completo de desarrollo seguro en Azure. Es una aplicación que podrían mostrar en entrevistas de trabajo, usar como base para proyectos consulting, o presentar a stakeholders técnicos en sus organizaciones actuales.
Los laboratorios de hoy serán intensamente prácticos y directamente aplicables a escenarios del mundo real. Implementarán cada concepto discutido usando las mismas herramientas y técnicas que usan equipos de desarrollo en Microsoft, Netflix, y otras organizaciones que operan a escala global.
La mentalidad para las sesiones finales: Estamos construyendo no solo una aplicación, sino dominio de principios y patrones que pueden aplicar a cualquier proyecto futuro. Es educación que será relevante por años mientras las tecnologías específicas evolucionan.
________________________________________
Diapositiva 25: Cierre y Labs (3 minutos)
¡Hemos completado una sesión intensiva que los ha equipado con capacidades de arquitectura de seguridad de nivel empresarial! En estas tres horas y media, han adquirido conocimiento y habilidades que normalmente requieren meses de experiencia práctica y múltiples proyectos para dominar.
Los laboratorios prácticos que ejecutarán ahora durante los próximos 70 minutos son donde la teoría se materializa en aplicaciones funcionando que podrían desplegar en ambientes de producción reales.
Lab 34: Diseño de arquitectura de aplicación segura (15 minutos) - Aquí crearán el blueprint completo de SecureShop. No van a codificar todavía - van a diseñar. Definirán la estructura de proyectos, mapearán flujos de datos entre componentes, identificarán puntos de integración con Azure AD y Key Vault, y documentarán decisiones de seguridad arquitectónicas. Es el tipo de ejercicio que arquitectos senior realizan antes de que cualquier desarrollador toque código.
Lab 35: Implementación de la base de la aplicación web .NET Core (20 minutos) - Aquí es donde construyen los fundamentos. Configurarán la solución multi-proyecto, implementarán middleware de seguridad, establecerán el contexto de Entity Framework con auditoría automática, y configurarán validación de entrada robusta. Al final de este lab, tendrán una aplicación que compila y ejecuta con características de seguridad integradas.
Lab 36: Integración con Azure AD y configuración de roles (20 minutos) - El laboratorio donde todo se conecta. Registrarán la aplicación en Azure AD, implementarán flujos de autenticación OAuth 2.0/OpenID Connect, configurarán claims transformation, y establecerán autorización basada en roles. Este es el punto donde su aplicación se convierte en un participante legítimo del ecosistema de identidad empresarial.
Lab 37: Configuración de Key Vault para la aplicación (15 minutos) - La implementación final donde establecerán gestión segura de secretos, configurarán servicios de cifrado, implementarán patrones de configuración segura, y probarán operaciones criptográficas usando Key Vault. Es donde eliminan cualquier vestigio de secretos hardcodeados y implementan gestión de material criptográfico de nivel bancario.
La progresión de estos laboratorios está diseñada para construir comprensión incrementalmente. Cada lab depende del anterior, pero también introduce conceptos nuevos que se integran naturalmente con trabajo previo.
Al final de estos laboratorios, tendrán en sus computadoras una aplicación que:
•	Se autentica usando Azure AD con el mismo nivel de sofisticación que Office 365
•	Gestiona secretos usando Key Vault con protección HSM
•	Implementa autorización granular que puede escalar a organizaciones complejas
•	Registra auditoría comprensiva que cumple requerimientos regulatorios
•	Valida entrada robustamente contra vectores de ataque comunes
•	Cifra datos sensibles con técnicas de nivel empresarial
Los recursos de contacto permanecen disponibles para consultas continuas. El desarrollo seguro es un campo que evoluciona constantemente, y mantener conexiones con instructores y compañeros es invaluable para carrera profesional continua.
Recuerden: No están solo aprendiendo a usar herramientas específicas - están desarrollando intuición sobre cómo pensar en seguridad durante diseño de sistemas. Esta mentalidad será aplicable independientemente de qué tecnologías específicas usen en proyectos futuros.
¡Manos a la obra! Es momento de construir una aplicación que demuestre dominio profesional de desarrollo seguro en la nube.
¡Excelente progreso! Nos vemos el miércoles 30/07 a las 19:00 para completar esta obra maestra de seguridad!
________________________________________
Resumen Final del Instructor - Sesión 10
Resumen Final del Instructor
Esta sesión ha sido fundamental en transformar a los estudiantes de desarrolladores con conocimiento teórico de seguridad a arquitectos capaces de diseñar e implementar aplicaciones empresariales completamente seguras desde el primer día.
Los conceptos clave que deben retener:
•	Arquitectura secure-by-design con separación clara de responsabilidades
•	Integración empresarial con Azure AD usando OAuth 2.0 y OpenID Connect
•	Gestión de secretos con Key Vault y operaciones criptográficas avanzadas
•	Patrones de configuración segura que funcionan a través de múltiples ambientes
•	Auditoría comprensiva y testing automatizado de controles de seguridad
Para los laboratorios, asegúrense de que cada estudiante:
•	Pueda crear arquitecturas de aplicación que integren múltiples servicios Azure de forma segura
•	Tenga experiencia práctica configurando Azure AD y Key Vault desde cero
•	Comprenda cómo implementar validación de entrada, autorización, y auditoría
•	Pueda aplicar principios de configuración segura y gestión de secretos
•	Domine testing automatizado de funcionalidades de seguridad
La progresión hacia la sesión 11 debe incluir reflexión sobre cómo estos patrones arquitectónicos se aplican a proyectos reales, experimentación con características avanzadas de los servicios configurados, y preparación para completar la implementación con características de cifrado y firma digital.
Objetivos de los laboratorios prácticos (70 minutos):
1.	Lab 34: Diseño de arquitectura de aplicación segura (15 min)
o	Creación de documentación arquitectónica comprensiva
o	Mapeo de flujos de datos y puntos de integración
o	Identificación de controles de seguridad por capa
2.	Lab 35: Implementación de la base de la aplicación web .NET Core (20 min)
o	Configuración de estructura de solución multi-proyecto
o	Implementación de middleware de seguridad básico
o	Establecimiento de Entity Framework con auditoría
3.	Lab 36: Integración con Azure AD y configuración de roles (20 min)
o	Registro de aplicación en Azure AD con configuración completa
o	Implementación de autenticación OAuth 2.0/OpenID Connect
o	Configuración de autorización basada en claims y roles
4.	Lab 37: Configuración de Key Vault para la aplicación (15 min)
o	Creación y configuración de Key Vault con permisos apropiados
o	Integración de gestión de secretos en aplicación .NET
o	Testing de operaciones criptográficas básicas
Métricas de éxito para la sesión:
•	100% de estudiantes pueden explicar arquitectura secure-by-design
•	95% pueden configurar Azure AD integration desde cero
•	90% pueden implementar Key Vault integration funcional
•	85% comprenden patrones de testing de seguridad
Preparación para Sesión 11:
Los estudiantes ahora tienen base arquitectónica sólida. En la próxima sesión completarán la implementación con:
•	Cifrado avanzado de datos a nivel de aplicación
•	Firma digital usando certificados de Key Vault
•	Testing de penetración automatizado
•	Documentación de seguridad profesional
•	Preparación para evaluación final
Recursos adicionales recomendados:
•	Azure Architecture Center - Patrones de referencia para aplicaciones seguras
•	Microsoft Security Development Lifecycle - Metodologías de desarrollo seguro
•	OWASP Application Security Verification Standard - Lista de verificación comprensiva
•	Azure Well-Architected Framework - Pilares de seguridad para arquitecturas cloud
Notas para futuras iteraciones:
•	Considerar más tiempo para laboratorios prácticos (posiblemente 90 minutos)
•	Incluir más ejemplos de debugging de problemas de integración Azure AD
•	Desarrollar templates de proyecto más completos para acelerar setup inicial
•	Crear casos de estudio adicionales específicos de industrias reguladas
Esta sesión representa un hito crítico en el desarrollo profesional de los estudiantes, equipándolos con habilidades inmediatamente aplicables en ambientes empresariales y estableciendo fundación sólida para arquitectura de seguridad avanzada.

